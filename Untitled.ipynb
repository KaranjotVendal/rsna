{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f962ed0b-f9ef-4e3b-86f8-9ad3d3a4fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karanjotvendal/miniforge3/envs/thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "'''\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint'''\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "#from datamodules import Cifar10DataModule, MnistDataModule\n",
    "from plotting import show_failures, plot_loss_and_acc\n",
    "from utils import load_image, LossMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46804973-e280-4833-9c23-59567ff0fb9b",
   "metadata": {},
   "source": [
    "# HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37620e5d-29df-42e1-a0cf-e82f2f00c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/reduced_dataset/'\n",
    "MODEL = 'resnet18'\n",
    "BATCH_SIZE = 3\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "KFOLD= 10 \n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5c403-a48d-4cf3-a562-844275bb9b2c",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f802a964-597c-40da-b12d-47d5962dd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RACNet(nn.Module):\n",
    "    def __init__(self, NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        \n",
    "        ###self.CNN = timm.create_model('resnet50', pretrained=True, num_classes=0)\n",
    "        self.cnn = timm.create_model('resnet18', pretrained=True, num_classes=0, in_chans=1)\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "        in_features = self.cnn(torch.randn(2, 1, 112, 112)).shape[1]\n",
    "        #in_feature = self.cnn.fc.in_features\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=in_features, hidden_size=64, batch_first= True, bidirectional=False)\n",
    "        \n",
    "        self.fc = nn.Linear(16256, 32, bias=True)\n",
    "        self.classifier = nn.Linear(32, NUM_CLASSES, bias=True)\n",
    "\n",
    "    def forward(self, x, org):\n",
    "        # x shape: BxTxCxHxW\n",
    "        batch_size, timesteps, C, H, W = x.size()\n",
    "        c_in = x.view(batch_size * timesteps, C, H, W)\n",
    "        print('reshape input', c_in.shape)\n",
    "        \n",
    "        mask = self.mask_layer(org)\n",
    "        \n",
    "        out = self.cnn(c_in)\n",
    "        print('CNN ouput', out.shape)\n",
    "        \n",
    "        rnn_in = out.view(batch_size, timesteps, -1)\n",
    "        print('reshaped rnn_in', rnn_in.shape)\n",
    "        out, hd = self.rnn(rnn_in)\n",
    "        \n",
    "        #out =F.relu(self.RNN(out))\n",
    "        print('RNN ouput', out.shape)\n",
    "        #print('RNN hidden', hd.shape)\n",
    "        \n",
    "        out = out * mask\n",
    "        print('mask ouput', out.shape)\n",
    "        \n",
    "        batch, timesteps, r_features = out.size() \n",
    "        #out = out.view(batch_size, timesteps * r_features)\n",
    "        out = out.reshape(batch_size, timesteps * r_features)\n",
    "        print('reshaped masked output', out.shape)\n",
    "        \n",
    "        out = F.relu(self.fc(out))\n",
    "        print('fc ouput', out.shape)\n",
    "\n",
    "        logits = self.classifier(out)\n",
    "        print('classifier ouput', logits.shape)\n",
    "        \n",
    "        output = F.softmax(logits, dim=1)\n",
    "        print('prb ouput', output.shape)\n",
    "        #output = F.softmax(logits) #[prob 0, prob 1]\n",
    "\n",
    "        #return output\n",
    "        return logits, output\n",
    "\n",
    "    def mask_layer(self, org):\n",
    "        masks = []\n",
    "        for i in org:\n",
    "            dup = 254 - i\n",
    "            mask_1 = torch.ones(i, 64)\n",
    "            mask_0 = torch.zeros(dup, 64)\n",
    "            mask = torch.cat((mask_1, mask_0), 0)\n",
    "            masks.append(mask)\n",
    "            #print(mask.shape)\n",
    "        masks = torch.stack(masks).to(device='cuda')\n",
    "        print('masks', masks.shape)\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a4b72-01cd-4e3c-bd03-17df7d9b6252",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970d1485-453f-4a1b-a84e-d46d79e28ad6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNAdataset(Dataset):\n",
    "    def __init__(self, patient_path, paths, targets, n_slices, img_size, transform=None):\n",
    "        #(self, './data/reduced_dataset/', t['xtrain'],t['ytrain'], 254, 112, transform)\n",
    "        self.patient_path = patient_path\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.n_slices = n_slices\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "          \n",
    "    def __len__(self):\n",
    "        #print(len(self.paths))\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def padding(self, paths):\n",
    "        \n",
    "        images=[load_image(path) for path in paths]\n",
    "        org_size = len(images)\n",
    "\n",
    "        #if len(images) != 0:\n",
    "            \n",
    "        dup_len = 254 - len(images)\n",
    "        if org_size == 0:\n",
    "            dup = torch.zeros(self.n_slices, 112, 112)\n",
    "        else:\n",
    "            dup = images[-1]\n",
    "        for i in range(dup_len):\n",
    "            images.append(dup)\n",
    "\n",
    "        images = [torch.tensor(image, dtype=torch.float32) for image in images]\n",
    "\n",
    "        #if len(images)==0:\n",
    "        #    images = torch.zeros(self.n_slices, 112, 112)\n",
    "        #else:\n",
    "        images = torch.stack(images)\n",
    "\n",
    "        return images, org_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        patient_path = os.path.join(self.patient_path, f'{str(_id).zfill(5)}/')\n",
    "\n",
    "        data = []\n",
    "        org = []\n",
    "        for t in [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]:\n",
    "            t_paths = sorted(\n",
    "                glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "            )\n",
    "            num_samples = self.n_slices\n",
    "            \n",
    "            image, org_size = self.padding(t_paths)\n",
    "            if image.shape[0] == 0:\n",
    "                image = torch.zeros(num_samples, self.img_size, self.img_size)\n",
    "            data.append(image)\n",
    "            org.append(org_size)\n",
    "            break\n",
    "            \n",
    "        data = torch.stack(data).transpose(0,1)\n",
    "        #print(data.shape)\n",
    "        #print('after transpose', data.shape)\n",
    "        y = torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        return {\"X\": data.float(), \"y\": y, 'org':org}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5a330-44fe-42c0-bcc7-b9f6e84850d0",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52d624a-d4c4-46d9-93ed-60f52f66ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        epochs,\n",
    "        loss_meter, \n",
    "        fold\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.loss_meter = loss_meter\n",
    "        self.hist = {'test_acc':[],\n",
    "                     'test_f1':[],\n",
    "                     'test_roc':[],\n",
    "                     'train_loss':[],\n",
    "                     'train_acc':[],\n",
    "                     'train_f1': [],\n",
    "                     'train_roc': [],\n",
    "                    }\n",
    "        \n",
    "        self.best_valid_score = -np.inf\n",
    "        self.best_valid_loss = np.inf\n",
    "        self.best_f_score = 0\n",
    "        self.n_patience = 0\n",
    "        self.fold = fold\n",
    "\n",
    "        self.record = {'test_loss':[],\n",
    "                    'test_acc':[],\n",
    "                     'test_f1':[],\n",
    "                     'test_roc':[],\n",
    "                     'train_loss':[],\n",
    "                     'train_acc':[],\n",
    "                     'train_f1': [],\n",
    "                     'train_roc': [],\n",
    "                    }\n",
    "        \n",
    "        \n",
    "    def fit(self, epochs, train_loader, save_path, patience):\n",
    "        train_time = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            t = time.time()\n",
    "            self.model.train()\n",
    "            train_loss = self.loss_meter()\n",
    "            train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro').to(self.device)\n",
    "            train_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            \n",
    "            for idx, batch in enumerate(train_loader):\n",
    "                \n",
    "                features = batch['X'].to(self.device)\n",
    "                targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                org = batch['org']\n",
    "                    \n",
    "                ### FORWARD AND BACK PROP\n",
    "                logits, probs = self.model(features, org)\n",
    "                loss = self.criterion(logits, targets)\n",
    "                \n",
    "                train_loss.update(loss.detach().item())\n",
    "                train_acc.update(probs, targets)\n",
    "                train_f1.update(probs, targets)\n",
    "                train_auroc.update(probs, targets)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()  \n",
    "            \n",
    "                #print(f'Epoch: {epoch+1}/{epochs} | Loss: {loss:.5f} | Accuracy: {train_acc:.4f}% | F1 Score: {train_f1:.4f} | AUROC: {train_roc:.4f} | Time: {int(time.time() - t)}')\n",
    "            \n",
    "            _loss = train_loss.avg\n",
    "            _acc = train_acc.compute\n",
    "            _f1 = train_f1.compute\n",
    "            _roc = train_auroc.compute\n",
    "            \n",
    "            self.hist['train_loss'].append(_loss)\n",
    "            self.hist['train_acc'].append(_acc)\n",
    "            self.hist['train_f1'].append(_f1)\n",
    "            self.hist['train_auroc'].append(_roc)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}/{epochs} | Loss: {_loss:.5f} | Accuracy: {_acc:.4f}% | F1 Score: {_f1:.4f} | AUROC: {_roc:.4f} | Time: {time.time() - t}')\n",
    "            \n",
    "            \n",
    "        avg_loss = np.mean(self.hist['train_loss'])\n",
    "        avg_acc = np.mean(self.hist['train_acc'])\n",
    "        avg_f1 = np.mean(self.hist['train_f1'])\n",
    "        avg_auroc = np.mean(self.hist['train_auroc'])\n",
    "\n",
    "        print(f'Epoch Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        #return avg_loss, avg_acc, avg_f1, avg_auroc\n",
    "        \n",
    "        \n",
    "        #testing------------------\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        test_time = time.time()\n",
    "        test_loss = self.loss_meter()\n",
    "        test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')        \n",
    "        test_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2)\n",
    "        \n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            \n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                        \n",
    "                for idx, batch in enumerate(test_loader):\n",
    "                    \n",
    "                    features = batch['X'].to(self.device)\n",
    "                    #targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                    targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                    \n",
    "                    org = batch['org']\n",
    "                    \n",
    "                    logits, probas = self.model(features, org)\n",
    "                    loss = self.criterion(logits, targets)\n",
    "                \n",
    "                    test_loss.update(loss.detach().item())\n",
    "                    test_acc.update(probs, targets)\n",
    "                    test_f1.update(probs, targets)\n",
    "                    test_auroc.update(probs, targets)\n",
    "\n",
    "                _loss = train_loss.avg\n",
    "                _acc = train_acc.compute\n",
    "                _f1 = train_f1.compute\n",
    "                _roc = train_auroc.compute  \n",
    "\n",
    "                self.hist['test_loss'].append(_loss)\n",
    "                self.hist['test_acc'].append(_acc)\n",
    "                self.hist['test_f1'].append(_f1)\n",
    "                self.hist['test_auroc'].append(_roc)\n",
    "                \n",
    "\n",
    "                #print(f'Total Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "\n",
    "\n",
    "            avg_loss = np.mean(self.hist['test_loss'])\n",
    "            avg_acc = np.mean(self.hist['test_acc'])\n",
    "            avg_f1 = np.mean(self.hist['test_f1'])\n",
    "            avg_auroc = np.mean(self.hist['test_auroc'])\n",
    "\n",
    "            print(f'Testing Time: {(time.time() - test_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "            \n",
    "        return avg_loss, avg_acc, avg_f1, avg_auroc\n",
    "                        \n",
    "                \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"best_valid_score\": self.best_valid_score,\n",
    "                    \"best_f1_score\": self.best_f_score,\n",
    "                    \"n_epoch\": n_epoch,\n",
    "                },\n",
    "                save_path,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28894df-4758-4d6c-9c77-761da12e6c58",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0f882f-96ce-4254-aca6-e2e831afba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, epochs, n_fold, batch_size, num_worker, device):\n",
    "    \n",
    "    fold_acc = []\n",
    "    fold_loss = []\n",
    "    fold_auroc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_fold):\n",
    "        fold = _+1\n",
    "        folds_xtrain = np.load('./data/folds/xtrain.npy', allow_pickle=True)\n",
    "        folds_xtest = np.load('./data/folds/xtest.npy', allow_pickle=True)\n",
    "        folds_ytrain = np.load('./data/folds/ytrain.npy', allow_pickle=True)\n",
    "        folds_ytest = np.load('./data/folds/ytest.npy', allow_pickle=True)\n",
    "        \n",
    "        xtrain = folds_xtrain[_]\n",
    "        ytrain = folds_ytrain[_]\n",
    "        xtest = folds_xtest[_]\n",
    "        ytest = folds_ytest[_]\n",
    "        \n",
    "        print('-'*30)\n",
    "        print(f\"Fold {fold}\")\n",
    "\n",
    "        train_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtrain,  \n",
    "                        ytrain,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "    \n",
    "        test_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtest,  \n",
    "                        ytest,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "                    train_set,    \n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    num_workers=8,\n",
    "                )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "                    train_set,    \n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    num_workers=8,\n",
    "                )\n",
    "            \n",
    "        model = RACNet(NUM_CLASSES)\n",
    "        model = model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        criterion = F.cross_entropy\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model, \n",
    "            device, \n",
    "            optimizer, \n",
    "            criterion,\n",
    "            epochs,\n",
    "            LossMeter, \n",
    "            fold\n",
    "        )\n",
    "        \n",
    "        trainer.fit(epochs,\n",
    "                    train_loader,\n",
    "                    './checkpoints/f\"best-model-{fold}.pth',\n",
    "                    5)\n",
    "                        \n",
    "        #trainer.plot_loss()\n",
    "        #trainer.plot_score()\n",
    "        #trainer.plot_fscore()\n",
    "                \n",
    "        #test\n",
    "        loss, test_acc, test_f1, test_auroc = Trainer.test(test_loader)\n",
    "        fold_loss.append(loss)\n",
    "        fold_acc.append(test_acc)\n",
    "        fold_f1.append(test_f1)\n",
    "        fold_auroc.append(test_auroc)    \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    '''wandb.log({\n",
    "         'Avg Test f1 score': np.mean(test_fscore),\n",
    "         'Avg Train f1 score': np.mean(f_scores)\n",
    "         })'''\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print('Avg loss {:.5f}'.format(np.mean(losses)))\n",
    "    print('Avg score {:.5f}'.format(np.mean(scores)))\n",
    "    print('Avg Train f1_score {:.5f}'.format(np.mean(f_scores)))\n",
    "    print('Avg Test f1_score {:.5f}'.format(np.mean(test_fscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7b332-5d7a-4846-be16-ce5eb997b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fold 1\n",
      "reshape input torch.Size([254, 1, 112, 112])\n",
      "masks torch.Size([1, 254, 64])\n",
      "CNN ouput torch.Size([254, 512])\n",
      "reshaped rnn_in torch.Size([1, 254, 512])\n",
      "RNN ouput torch.Size([1, 254, 64])\n",
      "mask ouput torch.Size([1, 254, 64])\n",
      "reshaped masked output torch.Size([1, 16256])\n",
      "fc ouput torch.Size([1, 32])\n",
      "classifier ouput torch.Size([1, 2])\n",
      "prb ouput torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "train(PATH, NUM_EPOCHS, KFOLD, BATCH_SIZE, NUM_WORKERS, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa8a9e-0f5e-49db-a7c1-cf5d380c653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff070a4-97ab-47fc-b89e-eb86a18bc9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a39bdd-30b2-423f-9273-83120b85bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e89e90-b548-487b-a8f8-594ab413b857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b854f-f286-461f-b24e-ab6d4aa3c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147b5f1-1ce3-4887-a0e2-d046f40e3930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5307b-e765-4e8a-978c-ed4a559e31d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43922d-cf92-4664-8054-2c175de2686b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87e121-fe17-4972-a838-e67240811a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab22c2-2a22-4b3c-b5cf-cb51887c1007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1ff0a-0a3d-4e5b-a4f2-455d31f3eddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da24c94-3a29-4f66-93b3-091cf9f2f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fold 3\n"
     ]
    }
   ],
   "source": [
    "folds_xtrain = np.load('./data/folds/xtrain.npy', allow_pickle=True)\n",
    "folds_xtest = np.load('./data/folds/xtest.npy', allow_pickle=True)\n",
    "folds_ytrain = np.load('./data/folds/ytrain.npy', allow_pickle=True)\n",
    "folds_ytest = np.load('./data/folds/ytest.npy', allow_pickle=True)\n",
    "\n",
    "xtrain = folds_xtrain[4]\n",
    "ytrain = folds_ytrain[4]\n",
    "xtest = folds_xtest[4]\n",
    "ytest = folds_ytest[4]\n",
    "\n",
    "print('-'*30)\n",
    "print(f\"Fold {'3'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a3c05b-4922-482d-aec8-152d40c21a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_retriever = RSNAdataset(\n",
    "    'data/reduced_dataset/',\n",
    "    xtrain,  \n",
    "    ytrain,\n",
    "    n_slices=254,\n",
    "    img_size=112,\n",
    "    transform=None\n",
    "        )\n",
    "\n",
    "test_retriever = RSNAdataset(\n",
    "    'data/reduced_dataset/',\n",
    "    xtest,  \n",
    "    ytest,\n",
    "    n_slices=254,\n",
    "    img_size=112,\n",
    "    transform=None\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_retriever,    \n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_retriever,    \n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "# Checking the dataset\n",
    "for batch in train_loader:  \n",
    "    print('Image batch dimensions:', batch['X'].shape)\n",
    "    print('Image Class dimensions:', batch['y'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3ccb3-f70c-47c1-b2b7-52d7a64472c3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b773e-0ed6-4539-b4df-377d4866274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RACNet(NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4b7f6-bf40-4a7d-a632-0e27f3964434",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(PATH, NUM_EPOCH, N_kFOLD, BATCH_SIZE, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5b05-17eb-42c4-a53a-15f708daf27b",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525a121-2caa-46c2-857d-411aae1eae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9279c8-5516-4908-86c3-db9f7caea158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecNet()\n",
    "model.to(device='cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = F.cross_entropy\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f1650b-8b1b-4830-a17a-302439aa40da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader output torch.Size([1, 254, 1, 112, 112])\n",
      "train_loader targets torch.Size([1])\n",
      "train org tensor([110])\n",
      "reshape input torch.Size([254, 1, 112, 112])\n",
      "masks torch.Size([1, 254, 64])\n",
      "CNN ouput torch.Size([254, 512])\n",
      "reshaped rnn_in torch.Size([1, 254, 512])\n",
      "RNN ouput torch.Size([1, 254, 64])\n",
      "mask ouput torch.Size([1, 254, 64])\n",
      "reshaped masked output torch.Size([1, 16256])\n",
      "fc ouput torch.Size([1, 32])\n",
      "classifier ouput torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader, 1):\n",
    "    X = batch[0]['X'].to(device='cuda')\n",
    "    print('train_loader output',X.shape)\n",
    "    y = batch[0]['y'].to(device='cuda')\n",
    "    print('train_loader targets',y.shape)\n",
    "    org = batch[1][0]\n",
    "    print('train org', org)\n",
    "    #count += 1\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    outputs = model(X, org).squeeze(1)\n",
    "    break\n",
    "    #print('prob outputs', outputs.shape)\n",
    "    \n",
    "    #loss = criterion(outputs, y)\n",
    "    #loss.backward()\n",
    "\n",
    "    #train_loss.update(loss.detach().item())\n",
    "    #train_score.update(targets, outputs.detach())\n",
    "    \n",
    "    #self.optimizer.step()\n",
    "    \n",
    "    #_loss, _score = train_loss.avg, train_score.avg\n",
    "    #message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}, train_f1: {:.5f}'\n",
    "    #self.info_message(message, step, len(train_loader), _loss, _score, ff, end=\"\\r\")\n",
    "\n",
    "    #f_score = ff_score.get_score()\n",
    "    #return train_loss.avg, train_score.avg, f_score, int(time.time() - t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264f76d-8b75-4fc3-9ab7-70bda1eface7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b2d6a9-46bf-4d18-ac9b-a763b699f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict, org = train_retriever[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07ff37b-448a-4998-bdf5-0b1612bc38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dict['X']\n",
    "targets = dict['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacb7f55-52bc-4c85-a5f4-9c54157f6d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 1, 112, 112])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape\n",
    "#targets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1957793-d329-426b-93c5-336a290688f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbc7194-6d55-43e0-be38-c608ebab3e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22376b-155f-4e62-a416-cf7fedc97274",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = batch.to(device='cuda')\n",
    "X = X.unsqueeze(0)\n",
    "print(X.shape)\n",
    "y = targets.to(device='cuda')\n",
    "print(y.shape)\n",
    "\n",
    "#self.optimizer.zero_grad()\n",
    "outputs = model(X, org).squeeze()\n",
    "#outputs = outputs.squeeze()\n",
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef909f1e-8865-46d9-94ef-46f35e0ca4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('*convnext*', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d9bfd-6e91-4ec5-bd5d-b3d438e5051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4f61897-9036-4f2b-9b34-411ef52c4273",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled shape: 2048\n",
      "Identity()\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet50', pretrained=True, num_classes=0, in_chans=1)\n",
    "#m = res(torch.randn(2, 3, 224, 224))\n",
    "res.reset_classifier(0)\n",
    "o = res(torch.randn(2, 1, 112, 112))\n",
    "print(f'Pooled shape: {o.shape[1]}')\n",
    "print(res.fc)\n",
    "in_features = res(torch.randn(2, 1, 112, 112)).shape[1]\n",
    "print(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b43ceb-ee6e-4793-ab3b-f5c40ef81e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [torch.tensor(frame, dtype=torch.float32) for frame in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5abc94e3-6372-4562-9c0b-1f6c0a7adf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "073d78be-7900-41a5-89a0-bb7e04d6c7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 112, 112])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c0666-934a-4461-9e95-a8ea47e03f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a 'Karanjot Vendal' -v -p torch --iversion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

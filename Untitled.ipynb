{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f962ed0b-f9ef-4e3b-86f8-9ad3d3a4fd62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from train import train\n",
    "#from datamodules import RSNAdataset\n",
    "from models import *\n",
    "from plotting import show_failures, plot_loss_and_acc\n",
    "from utils import load_image, LossMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b10c32-53bd-4884-9d04-e9d2a1243015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46804973-e280-4833-9c23-59567ff0fb9b",
   "metadata": {},
   "source": [
    "# HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37620e5d-29df-42e1-a0cf-e82f2f00c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/reduced_dataset/'\n",
    "MODEL = 'resnet18'\n",
    "BATCH_SIZE = 3\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "KFOLD= 2\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5c403-a48d-4cf3-a562-844275bb9b2c",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5005f8-81ed-4ee7-b6d4-99d3c48f5fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RACNet(\n",
       "  (cnn): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (rnn): GRU(512, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=16256, out_features=32, bias=True)\n",
       "  (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RACNet(MODEL, NUM_CLASSES)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a4b72-01cd-4e3c-bd03-17df7d9b6252",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43137bc-6fe0-4cae-9b87-c894bf2270c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fold 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folds_xtrain = np.load('./data/folds/new_folds/xtrain.npy', allow_pickle=True)\n",
    "folds_xtest = np.load('./data/folds/new_folds/xtest.npy', allow_pickle=True)\n",
    "folds_ytrain = np.load('./data/folds/new_folds/ytrain.npy', allow_pickle=True)\n",
    "folds_ytest = np.load('./data/folds/new_folds/ytest.npy', allow_pickle=True)\n",
    "\n",
    "xtrain = folds_xtrain[1]\n",
    "ytrain = folds_ytrain[1]\n",
    "xtest = folds_xtest[1]\n",
    "ytest = folds_ytest[1]\n",
    "\n",
    "print('-'*30)\n",
    "print(f\"Fold {0}\")\n",
    "\n",
    "\n",
    "train_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtrain,  \n",
    "                        ytrain,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "    \n",
    "test_set = RSNAdataset(\n",
    "                './data/reduced_dataset/',\n",
    "                xtest,  \n",
    "                ytest,\n",
    "                n_slices=254,\n",
    "                img_size=112,\n",
    "                transform=None\n",
    "                    )\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_set,    \n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "            num_workers= NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "            test_set,    \n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8051d-a7fc-4869-a651-47e8e5975de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RACNet(MODEL, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = F.cross_entropy\n",
    "#test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "##test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')       \n",
    "#test_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "test_pred = []\n",
    "test_targets = []\n",
    "preds = []\n",
    "\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = batch['X'].to(DEVICE)\n",
    "        targets = batch['y'].to(DEVICE)\n",
    "        \n",
    "        org = batch['org']\n",
    "        #print(org)\n",
    "        \n",
    "        logits, probs = model(features, org)\n",
    "        predicted_class = probs.argmax(dim=1)\n",
    "        \n",
    "        test_pred.append(predicted_class)\n",
    "        test_targets.append(targets)\n",
    "        preds.append(probs)\n",
    "        print('probs shape:',probs.shape)\n",
    "        print('targets shape:', targets.shape)\n",
    "        \n",
    "        print('------BATCH ENDING-------')\n",
    "\n",
    "test_pred = torch.cat(test_pred)\n",
    "test_targets = torch.cat(test_targets)\n",
    "preds = torch.cat(preds)\n",
    "\n",
    "print('test preds:', test_pred)\n",
    "print('test preds:', test_pred.shape)\n",
    "print('test preds flatten:', test_pred.flatten().shape)\n",
    "\n",
    "print('test_target:', test_targets)\n",
    "print('test_target:', test_targets.shape)\n",
    "print('test_target flatten:', test_targets.flatten().shape)\n",
    "\n",
    "print('preds :', preds)\n",
    "print('preds :', preds.shape)\n",
    "#preds = torch.cat(preds)\n",
    "\n",
    "#acc = test_acc(probs, targets)\n",
    "#f1 = test_f1(test_pred, test_targets)\n",
    "#auroc = test_auroc(preds, test_targets)             \n",
    "        \n",
    "#print(f\"Testing Time: {(time.time() - test_time)/60:.2f} min | Accuracy: {acc:.2f}% | F1 Score: {f1:.4f} | AUROC: {auroc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72fe24-bece-4e23-a9f7-eecbd5cfe95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd9a00-d2b1-4682-a8a4-243b66517d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f44fc-60eb-46e5-8e12-d9dfab0bda3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85487709-653d-427f-aff1-5cda8f07285d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "facd7dea-2617-4090-a60b-87f9e0cd8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RACNet(NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = F.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ae08f-bfb8-4e01-9194-2ba68a6cbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    #t = time.time()\n",
    "    model.train()\n",
    "    train_loss = LossMeter()\n",
    "    #train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "    #train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro').to(self.device)\n",
    "    #train_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        features = batch['X'].to(DEVICE)\n",
    "        targets = batch['y'].type(torch.cuda.LongTensor).to(DEVICE)\n",
    "        org = batch['org']\n",
    "\n",
    "        print('features shape:',features.shape)\n",
    "        print('targets shape:',targets.shape)\n",
    "        print('org shape:',org)\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probs = model(features, org)\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        print('logits shape:', logits.shape)\n",
    "        print('probs shape:', probs.shape)\n",
    "        \n",
    "        train_loss.update(loss.detach().item())\n",
    "        #train_acc.update(probs, targets)\n",
    "        #train_f1.update(probs, targets)\n",
    "        #train_auroc.update(probs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'-----------loss: {loss}--------------')\n",
    "    \n",
    "        #print(f'Epoch: {epoch+1}/{epochs} | Loss: {loss:.5f} | Accuracy: {train_acc:.4f}% | F1 Score: {train_f1:.4f} | AUROC: {train_roc:.4f} | Time: {int(time.time() - t)}')\n",
    "    \n",
    "    _loss = train_loss.avg\n",
    "    #_acc = train_acc.compute\n",
    "    #_f1 = train_f1.compute\n",
    "    #_roc = train_auroc.compute\n",
    "    \n",
    "    #self.hist['train_loss'].append(_loss)\n",
    "    ##self.hist['train_acc'].append(_acc)\n",
    "    #self.hist['train_f1'].append(_f1)\n",
    "    #self.hist['train_auroc'].append(_roc)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{epochs} | Loss: {_loss:.5f}')\n",
    "    \n",
    "    \n",
    "avg_loss = np.mean(self.hist['train_loss'])\n",
    "#avg_acc = np.mean(self.hist['train_acc'])\n",
    "#avg_f1 = np.mean(self.hist['train_f1'])\n",
    "#avg_auroc = np.mean(self.hist['train_auroc'])\n",
    "\n",
    "#print(f'Epoch Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5a330-44fe-42c0-bcc7-b9f6e84850d0",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52d624a-d4c4-46d9-93ed-60f52f66ca51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        epochs,\n",
    "        loss_meter, \n",
    "        fold\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.loss_meter = loss_meter\n",
    "        self.hist = {'test_acc':[],\n",
    "                     'test_f1':[],\n",
    "                     'test_roc':[],\n",
    "                     'train_loss':[],\n",
    "                     'train_acc':[],\n",
    "                     'train_f1': [],\n",
    "                     'train_roc': [],\n",
    "                    }\n",
    "        \n",
    "        self.best_valid_score = -np.inf\n",
    "        self.best_valid_loss = np.inf\n",
    "        self.best_f_score = 0\n",
    "        self.n_patience = 0\n",
    "        self.fold = fold\n",
    "\n",
    "        self.record = {'test_loss':[],\n",
    "                    'test_acc':[],\n",
    "                     'test_f1':[],\n",
    "                     'test_roc':[],\n",
    "                     'train_loss':[],\n",
    "                     'train_acc':[],\n",
    "                     'train_f1': [],\n",
    "                     'train_roc': [],\n",
    "                    }\n",
    "        \n",
    "        \n",
    "    def fit(self, epochs, train_loader, save_path, patience):\n",
    "        train_time = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            t = time.time()\n",
    "            self.model.train()\n",
    "            train_loss = self.loss_meter()\n",
    "            train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro').to(self.device)\n",
    "            train_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            \n",
    "            for idx, batch in enumerate(train_loader):\n",
    "                \n",
    "                features = batch['X'].to(self.device)\n",
    "                targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                org = batch['org']\n",
    "                    \n",
    "                ### FORWARD AND BACK PROP\n",
    "                logits, probs = self.model(features, org)\n",
    "                loss = self.criterion(logits, targets)\n",
    "                \n",
    "                train_loss.update(loss.detach().item())\n",
    "                train_acc.update(probs, targets)\n",
    "                train_f1.update(probs, targets)\n",
    "                train_auroc.update(probs, targets)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()  \n",
    "            \n",
    "                #print(f'Epoch: {epoch+1}/{epochs} | Loss: {loss:.5f} | Accuracy: {train_acc:.4f}% | F1 Score: {train_f1:.4f} | AUROC: {train_roc:.4f} | Time: {int(time.time() - t)}')\n",
    "            \n",
    "            _loss = train_loss.avg\n",
    "            _acc = train_acc.compute\n",
    "            _f1 = train_f1.compute\n",
    "            _roc = train_auroc.compute\n",
    "            \n",
    "            self.hist['train_loss'].append(_loss)\n",
    "            self.hist['train_acc'].append(_acc)\n",
    "            self.hist['train_f1'].append(_f1)\n",
    "            self.hist['train_auroc'].append(_roc)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}/{epochs} | Loss: {_loss:.5f} | Accuracy: {_acc:.4f}% | F1 Score: {_f1:.4f} | AUROC: {_roc:.4f} | Time: {time.time() - t}')\n",
    "            \n",
    "            \n",
    "        avg_loss = np.mean(self.hist['train_loss'])\n",
    "        avg_acc = np.mean(self.hist['train_acc'])\n",
    "        avg_f1 = np.mean(self.hist['train_f1'])\n",
    "        avg_auroc = np.mean(self.hist['train_auroc'])\n",
    "\n",
    "        print(f'Epoch Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        #return avg_loss, avg_acc, avg_f1, avg_auroc\n",
    "        \n",
    "        \n",
    "        #testing------------------\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        test_time = time.time()\n",
    "        test_loss = self.loss_meter()\n",
    "        test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')        \n",
    "        test_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2)\n",
    "        \n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            \n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                        \n",
    "                for idx, batch in enumerate(test_loader):\n",
    "                    \n",
    "                    features = batch['X'].to(self.device)\n",
    "                    #targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                    targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                    \n",
    "                    org = batch['org']\n",
    "                    \n",
    "                    logits, probas = self.model(features, org)\n",
    "                    loss = self.criterion(logits, targets)\n",
    "                \n",
    "                    test_loss.update(loss.detach().item())\n",
    "                    test_acc.update(probs, targets)\n",
    "                    test_f1.update(probs, targets)\n",
    "                    test_auroc.update(probs, targets)\n",
    "\n",
    "                _loss = train_loss.avg\n",
    "                _acc = train_acc.compute\n",
    "                _f1 = train_f1.compute\n",
    "                _roc = train_auroc.compute  \n",
    "\n",
    "                self.hist['test_loss'].append(_loss)\n",
    "                self.hist['test_acc'].append(_acc)\n",
    "                self.hist['test_f1'].append(_f1)\n",
    "                self.hist['test_auroc'].append(_roc)\n",
    "                \n",
    "\n",
    "                #print(f'Total Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "\n",
    "\n",
    "            avg_loss = np.mean(self.hist['test_loss'])\n",
    "            avg_acc = np.mean(self.hist['test_acc'])\n",
    "            avg_f1 = np.mean(self.hist['test_f1'])\n",
    "            avg_auroc = np.mean(self.hist['test_auroc'])\n",
    "\n",
    "            print(f'Testing Time: {(time.time() - test_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "            \n",
    "        return avg_loss, avg_acc, avg_f1, avg_auroc\n",
    "                        \n",
    "                \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"best_valid_score\": self.best_valid_score,\n",
    "                    \"best_f1_score\": self.best_f_score,\n",
    "                    \"n_epoch\": n_epoch,\n",
    "                },\n",
    "                save_path,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28894df-4758-4d6c-9c77-761da12e6c58",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0f882f-96ce-4254-aca6-e2e831afba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, epochs, n_fold, batch_size, num_worker, device):\n",
    "    \n",
    "    fold_acc = []\n",
    "    fold_loss = []\n",
    "    fold_auroc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_fold):\n",
    "        fold = _+1\n",
    "        folds_xtrain = np.load('./data/folds/xtrain.npy', allow_pickle=True)\n",
    "        folds_xtest = np.load('./data/folds/xtest.npy', allow_pickle=True)\n",
    "        folds_ytrain = np.load('./data/folds/ytrain.npy', allow_pickle=True)\n",
    "        folds_ytest = np.load('./data/folds/ytest.npy', allow_pickle=True)\n",
    "        \n",
    "        xtrain = folds_xtrain[_]\n",
    "        ytrain = folds_ytrain[_]\n",
    "        xtest = folds_xtest[_]\n",
    "        ytest = folds_ytest[_]\n",
    "        \n",
    "        print('-'*30)\n",
    "        print(f\"Fold {fold}\")\n",
    "\n",
    "        train_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtrain,  \n",
    "                        ytrain,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "    \n",
    "        test_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtest,  \n",
    "                        ytest,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "                    train_set,    \n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    num_workers=8,\n",
    "                )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "                    train_set,    \n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    num_workers=8,\n",
    "                )\n",
    "            \n",
    "        model = RACNet(NUM_CLASSES)\n",
    "        model = model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        criterion = F.cross_entropy\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model, \n",
    "            device, \n",
    "            optimizer, \n",
    "            criterion,\n",
    "            epochs,\n",
    "            LossMeter, \n",
    "            fold\n",
    "        )\n",
    "        \n",
    "        #trainer.fit(epochs,\n",
    "        #            train_loader,\n",
    "        #            './checkpoints/f\"best-model-{fold}.pth',\n",
    "        #            5)\n",
    "                        \n",
    "        #trainer.plot_loss()\n",
    "        #trainer.plot_score()\n",
    "        #trainer.plot_fscore()\n",
    "                \n",
    "        #test\n",
    "        loss, test_acc, test_f1, test_auroc = Trainer.test(test_loader)\n",
    "        #fold_loss.append(loss)\n",
    "        #fold_acc.append(test_acc)\n",
    "        #fold_f1.append(test_f1)\n",
    "        #fold_auroc.append(test_auroc)    \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    '''wandb.log({\n",
    "         'Avg Test f1 score': np.mean(test_fscore),\n",
    "         'Avg Train f1 score': np.mean(f_scores)\n",
    "         })'''\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print('Avg loss {:.5f}'.format(np.mean(losses)))\n",
    "    print('Avg score {:.5f}'.format(np.mean(scores)))\n",
    "    print('Avg Train f1_score {:.5f}'.format(np.mean(f_scores)))\n",
    "    print('Avg Test f1_score {:.5f}'.format(np.mean(test_fscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7b332-5d7a-4846-be16-ce5eb997b6bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(PATH, NUM_EPOCHS, KFOLD, BATCH_SIZE, NUM_WORKERS, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa8a9e-0f5e-49db-a7c1-cf5d380c653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff070a4-97ab-47fc-b89e-eb86a18bc9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a39bdd-30b2-423f-9273-83120b85bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e89e90-b548-487b-a8f8-594ab413b857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b854f-f286-461f-b24e-ab6d4aa3c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147b5f1-1ce3-4887-a0e2-d046f40e3930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5307b-e765-4e8a-978c-ed4a559e31d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43922d-cf92-4664-8054-2c175de2686b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87e121-fe17-4972-a838-e67240811a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab22c2-2a22-4b3c-b5cf-cb51887c1007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1ff0a-0a3d-4e5b-a4f2-455d31f3eddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da24c94-3a29-4f66-93b3-091cf9f2f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fold 3\n"
     ]
    }
   ],
   "source": [
    "folds_xtrain = np.load('./data/folds/xtrain.npy', allow_pickle=True)\n",
    "folds_xtest = np.load('./data/folds/xtest.npy', allow_pickle=True)\n",
    "folds_ytrain = np.load('./data/folds/ytrain.npy', allow_pickle=True)\n",
    "folds_ytest = np.load('./data/folds/ytest.npy', allow_pickle=True)\n",
    "\n",
    "xtrain = folds_xtrain[4]\n",
    "ytrain = folds_ytrain[4]\n",
    "xtest = folds_xtest[4]\n",
    "ytest = folds_ytest[4]\n",
    "\n",
    "print('-'*30)\n",
    "print(f\"Fold {'3'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a3c05b-4922-482d-aec8-152d40c21a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_retriever = RSNAdataset(\n",
    "    'data/reduced_dataset/',\n",
    "    xtrain,  \n",
    "    ytrain,\n",
    "    n_slices=254,\n",
    "    img_size=112,\n",
    "    transform=None\n",
    "        )\n",
    "\n",
    "test_retriever = RSNAdataset(\n",
    "    'data/reduced_dataset/',\n",
    "    xtest,  \n",
    "    ytest,\n",
    "    n_slices=254,\n",
    "    img_size=112,\n",
    "    transform=None\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_retriever,    \n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_retriever,    \n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "# Checking the dataset\n",
    "for batch in train_loader:  \n",
    "    print('Image batch dimensions:', batch['X'].shape)\n",
    "    print('Image Class dimensions:', batch['y'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3ccb3-f70c-47c1-b2b7-52d7a64472c3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b773e-0ed6-4539-b4df-377d4866274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RACNet(NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4b7f6-bf40-4a7d-a632-0e27f3964434",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(PATH, NUM_EPOCH, N_kFOLD, BATCH_SIZE, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5b05-17eb-42c4-a53a-15f708daf27b",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525a121-2caa-46c2-857d-411aae1eae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9279c8-5516-4908-86c3-db9f7caea158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecNet()\n",
    "model.to(device='cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = F.cross_entropy\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1650b-8b1b-4830-a17a-302439aa40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader, 1):\n",
    "    X = batch[0]['X'].to(device='cuda')\n",
    "    print('train_loader output',X.shape)\n",
    "    y = batch[0]['y'].to(device='cuda')\n",
    "    print('train_loader targets',y.shape)\n",
    "    org = batch[1][0]\n",
    "    print('train org', org)\n",
    "    #count += 1\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    outputs = model(X, org).squeeze(1)\n",
    "    break\n",
    "    #print('prob outputs', outputs.shape)\n",
    "    \n",
    "    #loss = criterion(outputs, y)\n",
    "    #loss.backward()\n",
    "\n",
    "    #train_loss.update(loss.detach().item())\n",
    "    #train_score.update(targets, outputs.detach())\n",
    "    \n",
    "    #self.optimizer.step()\n",
    "    \n",
    "    #_loss, _score = train_loss.avg, train_score.avg\n",
    "    #message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}, train_f1: {:.5f}'\n",
    "    #self.info_message(message, step, len(train_loader), _loss, _score, ff, end=\"\\r\")\n",
    "\n",
    "    #f_score = ff_score.get_score()\n",
    "    #return train_loss.avg, train_score.avg, f_score, int(time.time() - t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264f76d-8b75-4fc3-9ab7-70bda1eface7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b2d6a9-46bf-4d18-ac9b-a763b699f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict, org = train_retriever[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07ff37b-448a-4998-bdf5-0b1612bc38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dict['X']\n",
    "targets = dict['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacb7f55-52bc-4c85-a5f4-9c54157f6d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 1, 112, 112])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape\n",
    "#targets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1957793-d329-426b-93c5-336a290688f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbc7194-6d55-43e0-be38-c608ebab3e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22376b-155f-4e62-a416-cf7fedc97274",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = batch.to(device='cuda')\n",
    "X = X.unsqueeze(0)\n",
    "print(X.shape)\n",
    "y = targets.to(device='cuda')\n",
    "print(y.shape)\n",
    "\n",
    "#self.optimizer.zero_grad()\n",
    "outputs = model(X, org).squeeze()\n",
    "#outputs = outputs.squeeze()\n",
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef909f1e-8865-46d9-94ef-46f35e0ca4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legacy_seresnet18.in1k',\n",
       " 'resnet18.a1_in1k',\n",
       " 'resnet18.a2_in1k',\n",
       " 'resnet18.a3_in1k',\n",
       " 'resnet18.fb_ssl_yfcc100m_ft_in1k',\n",
       " 'resnet18.fb_swsl_ig1b_ft_in1k',\n",
       " 'resnet18.gluon_in1k',\n",
       " 'resnet18.tv_in1k',\n",
       " 'resnet18d.ra2_in1k',\n",
       " 'skresnet18.ra_in1k']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('*resnet18*', pretrained=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d9bfd-6e91-4ec5-bd5d-b3d438e5051c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4f61897-9036-4f2b-9b34-411ef52c4273",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled shape: 2048\n",
      "Identity()\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet50', pretrained=True, num_classes=0, in_chans=1)\n",
    "#m = res(torch.randn(2, 3, 224, 224))\n",
    "res.reset_classifier(0)\n",
    "o = res(torch.randn(2, 1, 112, 112))\n",
    "print(f'Pooled shape: {o.shape[1]}')\n",
    "print(res.fc)\n",
    "in_features = res(torch.randn(2, 1, 112, 112)).shape[1]\n",
    "print(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d881d-192e-493f-a204-5f731338e997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b43ceb-ee6e-4793-ab3b-f5c40ef81e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [torch.tensor(frame, dtype=torch.float32) for frame in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5abc94e3-6372-4562-9c0b-1f6c0a7adf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "073d78be-7900-41a5-89a0-bb7e04d6c7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 112, 112])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c0666-934a-4461-9e95-a8ea47e03f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a 'Karanjot Vendal' -v -p torch --iversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b36b3-ca2f-415b-8119-22b9f870db3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8fd15c1-1ec3-47f1-b51f-8bd6f144e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet50', pretrained=True, num_classes=2, in_chans=1)\n",
    "#m = res(torch.randn(2, 3, 224, 224))\n",
    "#res.reset_classifier(0)\n",
    "#o = res(torch.randn(2, 1, 112, 112))\n",
    "#print(f'Pooled shape: {o.shape[1]}')\n",
    "#print(res.fc)\n",
    "in_features = res(torch.randn(2, 1, 112, 112)).shape[1]\n",
    "print(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa3a0718-aa9a-43cb-b309-bceef48d33be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled shape: 2048\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet50', pretrained=True, num_classes=0, in_chans=1)\n",
    "o = res(torch.randn(2, 1, 112, 112))\n",
    "print(f'Pooled shape: {o.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b83f651-f09d-471a-b040-48205157106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled shape: 512\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet18', pretrained=True, num_classes=0, in_chans=1)\n",
    "o = res(torch.randn(2, 1, 112, 112))\n",
    "print(f'Pooled shape: {o.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cd31fe7-6685-4cb5-9d2c-892bfa48e2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled shape: 2048\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet50d.ra2_in1k', pretrained=True, num_classes=0, in_chans=1)\n",
    "o = res(torch.randn(2, 1, 112, 112))\n",
    "print(f'Pooled shape: {o.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "318bf25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled shape: 512\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet18.fb_swsl_ig1b_ft_in1k', pretrained=True, num_classes=0, in_chans=1)\n",
    "o = res(torch.randn(2, 1, 112, 112))\n",
    "print(f'Pooled shape: {o.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77e69ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): GlobalResponseNormMlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (grn): GlobalResponseNorm()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): NormMlpClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (pre_logits): Identity()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = timm.create_model('convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=True, num_classes=0, in_chans=1)\n",
    "res\n",
    "#o = res(torch.randn(2, 1, 112, 112))\n",
    "#print(f'Pooled shape: {o.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba3a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

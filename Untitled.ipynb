{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f962ed0b-f9ef-4e3b-86f8-9ad3d3a4fd62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karanjotvendal/miniforge3/envs/thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from datamodules import RSNAdataset\n",
    "from models import RACNet\n",
    "from plotting import show_failures, plot_loss_and_acc\n",
    "from utils import load_image, LossMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b10c32-53bd-4884-9d04-e9d2a1243015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46804973-e280-4833-9c23-59567ff0fb9b",
   "metadata": {},
   "source": [
    "# HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37620e5d-29df-42e1-a0cf-e82f2f00c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/reduced_dataset/'\n",
    "MODEL = 'resnet18'\n",
    "BATCH_SIZE = 3\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "KFOLD= 10 \n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5c403-a48d-4cf3-a562-844275bb9b2c",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a4b72-01cd-4e3c-bd03-17df7d9b6252",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43137bc-6fe0-4cae-9b87-c894bf2270c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fold 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folds_xtrain = np.load('./data/folds/new_folds/xtrain.npy', allow_pickle=True)\n",
    "folds_xtest = np.load('./data/folds/new_folds/xtest.npy', allow_pickle=True)\n",
    "folds_ytrain = np.load('./data/folds/new_folds/ytrain.npy', allow_pickle=True)\n",
    "folds_ytest = np.load('./data/folds/new_folds/ytest.npy', allow_pickle=True)\n",
    "\n",
    "xtrain = folds_xtrain[1]\n",
    "ytrain = folds_ytrain[1]\n",
    "xtest = folds_xtest[1]\n",
    "ytest = folds_ytest[1]\n",
    "\n",
    "print('-'*30)\n",
    "print(f\"Fold {0}\")\n",
    "\n",
    "\n",
    "train_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtrain,  \n",
    "                        ytrain,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "    \n",
    "test_set = RSNAdataset(\n",
    "                './data/reduced_dataset/',\n",
    "                xtest,  \n",
    "                ytest,\n",
    "                n_slices=254,\n",
    "                img_size=112,\n",
    "                transform=None\n",
    "                    )\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_set,    \n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "            num_workers= NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "            test_set,    \n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e8051d-a7fc-4869-a651-47e8e5975de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([1016, 1, 112, 112])\n",
      "CNN ouput torch.Size([1016, 512])\n",
      "reshaped rnn_in torch.Size([4, 254, 512])\n",
      "RNN ouput torch.Size([4, 254, 64])\n",
      "mask ouput torch.Size([4, 254, 64])\n",
      "reshaped masked output torch.Size([4, 16256])\n",
      "fc ouput torch.Size([4, 32])\n",
      "logits torch.Size([4, 2])\n",
      "classifier ouput torch.Size([4, 2])\n",
      "probs shape: torch.Size([4, 2])\n",
      "targets shape: torch.Size([4])\n",
      "------BATCH ENDING-------\n",
      "reshape input torch.Size([254, 1, 112, 112])\n",
      "CNN ouput torch.Size([254, 512])\n",
      "reshaped rnn_in torch.Size([1, 254, 512])\n",
      "RNN ouput torch.Size([1, 254, 64])\n",
      "mask ouput torch.Size([1, 254, 64])\n",
      "reshaped masked output torch.Size([1, 16256])\n",
      "fc ouput torch.Size([1, 32])\n",
      "logits torch.Size([1, 2])\n",
      "classifier ouput torch.Size([1, 2])\n",
      "probs shape: torch.Size([1, 2])\n",
      "targets shape: torch.Size([1])\n",
      "------BATCH ENDING-------\n",
      "test preds: tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
      "       device='cuda:0')\n",
      "test preds: torch.Size([117])\n",
      "test preds flatten: torch.Size([117])\n",
      "test_target: tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       device='cuda:0')\n",
      "test_target: torch.Size([117])\n",
      "test_target flatten: torch.Size([117])\n",
      "preds : tensor([[0.4985, 0.5015],\n",
      "        [0.5111, 0.4889],\n",
      "        [0.4896, 0.5104],\n",
      "        [0.5146, 0.4854],\n",
      "        [0.4899, 0.5101],\n",
      "        [0.4904, 0.5096],\n",
      "        [0.5204, 0.4796],\n",
      "        [0.4972, 0.5028],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.5182, 0.4818],\n",
      "        [0.5232, 0.4768],\n",
      "        [0.4897, 0.5103],\n",
      "        [0.5064, 0.4936],\n",
      "        [0.4895, 0.5105],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4911, 0.5089],\n",
      "        [0.4849, 0.5151],\n",
      "        [0.5242, 0.4758],\n",
      "        [0.4867, 0.5133],\n",
      "        [0.5087, 0.4913],\n",
      "        [0.5062, 0.4938],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.5210, 0.4790],\n",
      "        [0.4971, 0.5029],\n",
      "        [0.5234, 0.4766],\n",
      "        [0.4926, 0.5074],\n",
      "        [0.5150, 0.4850],\n",
      "        [0.5290, 0.4710],\n",
      "        [0.4896, 0.5104],\n",
      "        [0.4937, 0.5063],\n",
      "        [0.5059, 0.4941],\n",
      "        [0.4823, 0.5177],\n",
      "        [0.5210, 0.4790],\n",
      "        [0.5005, 0.4995],\n",
      "        [0.4880, 0.5120],\n",
      "        [0.4986, 0.5014],\n",
      "        [0.5024, 0.4976],\n",
      "        [0.4847, 0.5153],\n",
      "        [0.5083, 0.4917],\n",
      "        [0.4942, 0.5058],\n",
      "        [0.5074, 0.4926],\n",
      "        [0.4874, 0.5126],\n",
      "        [0.4990, 0.5009],\n",
      "        [0.4966, 0.5034],\n",
      "        [0.5011, 0.4989],\n",
      "        [0.5031, 0.4969],\n",
      "        [0.4891, 0.5109],\n",
      "        [0.5364, 0.4636],\n",
      "        [0.4994, 0.5006],\n",
      "        [0.4807, 0.5193],\n",
      "        [0.5258, 0.4742],\n",
      "        [0.5267, 0.4733],\n",
      "        [0.4958, 0.5042],\n",
      "        [0.4934, 0.5066],\n",
      "        [0.4881, 0.5119],\n",
      "        [0.5407, 0.4593],\n",
      "        [0.5131, 0.4869],\n",
      "        [0.4946, 0.5054],\n",
      "        [0.5015, 0.4985],\n",
      "        [0.4930, 0.5070],\n",
      "        [0.5347, 0.4653],\n",
      "        [0.4994, 0.5006],\n",
      "        [0.5099, 0.4901],\n",
      "        [0.5259, 0.4741],\n",
      "        [0.4943, 0.5057],\n",
      "        [0.4925, 0.5075],\n",
      "        [0.5371, 0.4629],\n",
      "        [0.4908, 0.5092],\n",
      "        [0.4856, 0.5144],\n",
      "        [0.4905, 0.5095],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.4865, 0.5135],\n",
      "        [0.5101, 0.4899],\n",
      "        [0.5449, 0.4551],\n",
      "        [0.4978, 0.5022],\n",
      "        [0.4876, 0.5124],\n",
      "        [0.5072, 0.4928],\n",
      "        [0.5252, 0.4748],\n",
      "        [0.5006, 0.4994],\n",
      "        [0.5130, 0.4870],\n",
      "        [0.4877, 0.5123],\n",
      "        [0.5289, 0.4711],\n",
      "        [0.4850, 0.5150],\n",
      "        [0.4880, 0.5120],\n",
      "        [0.4963, 0.5037],\n",
      "        [0.4889, 0.5111],\n",
      "        [0.4889, 0.5111],\n",
      "        [0.5195, 0.4805],\n",
      "        [0.4898, 0.5102],\n",
      "        [0.5352, 0.4648],\n",
      "        [0.4874, 0.5126],\n",
      "        [0.5061, 0.4939],\n",
      "        [0.5023, 0.4977],\n",
      "        [0.4950, 0.5050],\n",
      "        [0.5021, 0.4979],\n",
      "        [0.5272, 0.4728],\n",
      "        [0.4884, 0.5116],\n",
      "        [0.4936, 0.5064],\n",
      "        [0.5626, 0.4374],\n",
      "        [0.4994, 0.5006],\n",
      "        [0.4992, 0.5008],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.5037, 0.4963],\n",
      "        [0.4954, 0.5046],\n",
      "        [0.5085, 0.4915],\n",
      "        [0.5151, 0.4849],\n",
      "        [0.4915, 0.5085],\n",
      "        [0.4907, 0.5093],\n",
      "        [0.4954, 0.5046],\n",
      "        [0.4891, 0.5109],\n",
      "        [0.5253, 0.4747],\n",
      "        [0.4970, 0.5030],\n",
      "        [0.5401, 0.4599],\n",
      "        [0.5170, 0.4830],\n",
      "        [0.5363, 0.4637],\n",
      "        [0.5023, 0.4977],\n",
      "        [0.5187, 0.4813]], device='cuda:0')\n",
      "preds : torch.Size([117, 2])\n"
     ]
    }
   ],
   "source": [
    "model = RACNet(MODEL, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = F.cross_entropy\n",
    "#test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "##test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')       \n",
    "#test_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "test_pred = []\n",
    "test_targets = []\n",
    "preds = []\n",
    "\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = batch['X'].to(DEVICE)\n",
    "        targets = batch['y'].to(DEVICE)\n",
    "        \n",
    "        org = batch['org']\n",
    "        #print(org)\n",
    "        \n",
    "        logits, probs = model(features, org)\n",
    "        predicted_class = probs.argmax(dim=1)\n",
    "        \n",
    "        test_pred.append(predicted_class)\n",
    "        test_targets.append(targets)\n",
    "        preds.append(probs)\n",
    "        print('probs shape:',probs.shape)\n",
    "        print('targets shape:', targets.shape)\n",
    "        \n",
    "        print('------BATCH ENDING-------')\n",
    "\n",
    "test_pred = torch.cat(test_pred)\n",
    "test_targets = torch.cat(test_targets)\n",
    "preds = torch.cat(preds)\n",
    "\n",
    "print('test preds:', test_pred)\n",
    "print('test preds:', test_pred.shape)\n",
    "print('test preds flatten:', test_pred.flatten().shape)\n",
    "\n",
    "print('test_target:', test_targets)\n",
    "print('test_target:', test_targets.shape)\n",
    "print('test_target flatten:', test_targets.flatten().shape)\n",
    "\n",
    "print('preds :', preds)\n",
    "print('preds :', preds.shape)\n",
    "#preds = torch.cat(preds)\n",
    "\n",
    "#acc = test_acc(probs, targets)\n",
    "#f1 = test_f1(test_pred, test_targets)\n",
    "#auroc = test_auroc(preds, test_targets)             \n",
    "        \n",
    "#print(f\"Testing Time: {(time.time() - test_time)/60:.2f} min | Accuracy: {acc:.2f}% | F1 Score: {f1:.4f} | AUROC: {auroc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72fe24-bece-4e23-a9f7-eecbd5cfe95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd9a00-d2b1-4682-a8a4-243b66517d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f44fc-60eb-46e5-8e12-d9dfab0bda3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85487709-653d-427f-aff1-5cda8f07285d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "facd7dea-2617-4090-a60b-87f9e0cd8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RACNet(NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = F.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ae08f-bfb8-4e01-9194-2ba68a6cbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    #t = time.time()\n",
    "    model.train()\n",
    "    train_loss = LossMeter()\n",
    "    #train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "    #train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro').to(self.device)\n",
    "    #train_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        features = batch['X'].to(DEVICE)\n",
    "        targets = batch['y'].type(torch.cuda.LongTensor).to(DEVICE)\n",
    "        org = batch['org']\n",
    "\n",
    "        print('features shape:',features.shape)\n",
    "        print('targets shape:',targets.shape)\n",
    "        print('org shape:',org)\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probs = model(features, org)\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        print('logits shape:', logits.shape)\n",
    "        print('probs shape:', probs.shape)\n",
    "        \n",
    "        train_loss.update(loss.detach().item())\n",
    "        #train_acc.update(probs, targets)\n",
    "        #train_f1.update(probs, targets)\n",
    "        #train_auroc.update(probs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'-----------loss: {loss}--------------')\n",
    "    \n",
    "        #print(f'Epoch: {epoch+1}/{epochs} | Loss: {loss:.5f} | Accuracy: {train_acc:.4f}% | F1 Score: {train_f1:.4f} | AUROC: {train_roc:.4f} | Time: {int(time.time() - t)}')\n",
    "    \n",
    "    _loss = train_loss.avg\n",
    "    #_acc = train_acc.compute\n",
    "    #_f1 = train_f1.compute\n",
    "    #_roc = train_auroc.compute\n",
    "    \n",
    "    #self.hist['train_loss'].append(_loss)\n",
    "    ##self.hist['train_acc'].append(_acc)\n",
    "    #self.hist['train_f1'].append(_f1)\n",
    "    #self.hist['train_auroc'].append(_roc)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{epochs} | Loss: {_loss:.5f}')\n",
    "    \n",
    "    \n",
    "avg_loss = np.mean(self.hist['train_loss'])\n",
    "#avg_acc = np.mean(self.hist['train_acc'])\n",
    "#avg_f1 = np.mean(self.hist['train_f1'])\n",
    "#avg_auroc = np.mean(self.hist['train_auroc'])\n",
    "\n",
    "#print(f'Epoch Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5a330-44fe-42c0-bcc7-b9f6e84850d0",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52d624a-d4c4-46d9-93ed-60f52f66ca51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        epochs,\n",
    "        loss_meter, \n",
    "        fold\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.loss_meter = loss_meter\n",
    "        self.hist = {'test_acc':[],\n",
    "                     'test_f1':[],\n",
    "                     'test_roc':[],\n",
    "                     'train_loss':[],\n",
    "                     'train_acc':[],\n",
    "                     'train_f1': [],\n",
    "                     'train_roc': [],\n",
    "                    }\n",
    "        \n",
    "        self.best_valid_score = -np.inf\n",
    "        self.best_valid_loss = np.inf\n",
    "        self.best_f_score = 0\n",
    "        self.n_patience = 0\n",
    "        self.fold = fold\n",
    "\n",
    "        self.record = {'test_loss':[],\n",
    "                    'test_acc':[],\n",
    "                     'test_f1':[],\n",
    "                     'test_roc':[],\n",
    "                     'train_loss':[],\n",
    "                     'train_acc':[],\n",
    "                     'train_f1': [],\n",
    "                     'train_roc': [],\n",
    "                    }\n",
    "        \n",
    "        \n",
    "    def fit(self, epochs, train_loader, save_path, patience):\n",
    "        train_time = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            t = time.time()\n",
    "            self.model.train()\n",
    "            train_loss = self.loss_meter()\n",
    "            train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro').to(self.device)\n",
    "            train_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            \n",
    "            for idx, batch in enumerate(train_loader):\n",
    "                \n",
    "                features = batch['X'].to(self.device)\n",
    "                targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                org = batch['org']\n",
    "                    \n",
    "                ### FORWARD AND BACK PROP\n",
    "                logits, probs = self.model(features, org)\n",
    "                loss = self.criterion(logits, targets)\n",
    "                \n",
    "                train_loss.update(loss.detach().item())\n",
    "                train_acc.update(probs, targets)\n",
    "                train_f1.update(probs, targets)\n",
    "                train_auroc.update(probs, targets)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()  \n",
    "            \n",
    "                #print(f'Epoch: {epoch+1}/{epochs} | Loss: {loss:.5f} | Accuracy: {train_acc:.4f}% | F1 Score: {train_f1:.4f} | AUROC: {train_roc:.4f} | Time: {int(time.time() - t)}')\n",
    "            \n",
    "            _loss = train_loss.avg\n",
    "            _acc = train_acc.compute\n",
    "            _f1 = train_f1.compute\n",
    "            _roc = train_auroc.compute\n",
    "            \n",
    "            self.hist['train_loss'].append(_loss)\n",
    "            self.hist['train_acc'].append(_acc)\n",
    "            self.hist['train_f1'].append(_f1)\n",
    "            self.hist['train_auroc'].append(_roc)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}/{epochs} | Loss: {_loss:.5f} | Accuracy: {_acc:.4f}% | F1 Score: {_f1:.4f} | AUROC: {_roc:.4f} | Time: {time.time() - t}')\n",
    "            \n",
    "            \n",
    "        avg_loss = np.mean(self.hist['train_loss'])\n",
    "        avg_acc = np.mean(self.hist['train_acc'])\n",
    "        avg_f1 = np.mean(self.hist['train_f1'])\n",
    "        avg_auroc = np.mean(self.hist['train_auroc'])\n",
    "\n",
    "        print(f'Epoch Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        #return avg_loss, avg_acc, avg_f1, avg_auroc\n",
    "        \n",
    "        \n",
    "        #testing------------------\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        test_time = time.time()\n",
    "        test_loss = self.loss_meter()\n",
    "        test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')        \n",
    "        test_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2)\n",
    "        \n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            \n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                        \n",
    "                for idx, batch in enumerate(test_loader):\n",
    "                    \n",
    "                    features = batch['X'].to(self.device)\n",
    "                    #targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                    targets = batch['y'].type(torch.cuda.LongTensor).to(self.device)\n",
    "                    \n",
    "                    org = batch['org']\n",
    "                    \n",
    "                    logits, probas = self.model(features, org)\n",
    "                    loss = self.criterion(logits, targets)\n",
    "                \n",
    "                    test_loss.update(loss.detach().item())\n",
    "                    test_acc.update(probs, targets)\n",
    "                    test_f1.update(probs, targets)\n",
    "                    test_auroc.update(probs, targets)\n",
    "\n",
    "                _loss = train_loss.avg\n",
    "                _acc = train_acc.compute\n",
    "                _f1 = train_f1.compute\n",
    "                _roc = train_auroc.compute  \n",
    "\n",
    "                self.hist['test_loss'].append(_loss)\n",
    "                self.hist['test_acc'].append(_acc)\n",
    "                self.hist['test_f1'].append(_f1)\n",
    "                self.hist['test_auroc'].append(_roc)\n",
    "                \n",
    "\n",
    "                #print(f'Total Training Time: {(train.time() - start_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "\n",
    "\n",
    "            avg_loss = np.mean(self.hist['test_loss'])\n",
    "            avg_acc = np.mean(self.hist['test_acc'])\n",
    "            avg_f1 = np.mean(self.hist['test_f1'])\n",
    "            avg_auroc = np.mean(self.hist['test_auroc'])\n",
    "\n",
    "            print(f'Testing Time: {(time.time() - test_time)/60} min | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.4f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC: {avg_auroc:.4f}')\n",
    "            \n",
    "        return avg_loss, avg_acc, avg_f1, avg_auroc\n",
    "                        \n",
    "                \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"best_valid_score\": self.best_valid_score,\n",
    "                    \"best_f1_score\": self.best_f_score,\n",
    "                    \"n_epoch\": n_epoch,\n",
    "                },\n",
    "                save_path,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28894df-4758-4d6c-9c77-761da12e6c58",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0f882f-96ce-4254-aca6-e2e831afba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, epochs, n_fold, batch_size, num_worker, device):\n",
    "    \n",
    "    fold_acc = []\n",
    "    fold_loss = []\n",
    "    fold_auroc = []\n",
    "    fold_f1 = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_fold):\n",
    "        fold = _+1\n",
    "        folds_xtrain = np.load('./data/folds/xtrain.npy', allow_pickle=True)\n",
    "        folds_xtest = np.load('./data/folds/xtest.npy', allow_pickle=True)\n",
    "        folds_ytrain = np.load('./data/folds/ytrain.npy', allow_pickle=True)\n",
    "        folds_ytest = np.load('./data/folds/ytest.npy', allow_pickle=True)\n",
    "        \n",
    "        xtrain = folds_xtrain[_]\n",
    "        ytrain = folds_ytrain[_]\n",
    "        xtest = folds_xtest[_]\n",
    "        ytest = folds_ytest[_]\n",
    "        \n",
    "        print('-'*30)\n",
    "        print(f\"Fold {fold}\")\n",
    "\n",
    "        train_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtrain,  \n",
    "                        ytrain,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "    \n",
    "        test_set = RSNAdataset(\n",
    "                        './data/reduced_dataset/',\n",
    "                        xtest,  \n",
    "                        ytest,\n",
    "                        n_slices=254,\n",
    "                        img_size=112,\n",
    "                        transform=None\n",
    "                            )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "                    train_set,    \n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    num_workers=8,\n",
    "                )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "                    train_set,    \n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    num_workers=8,\n",
    "                )\n",
    "            \n",
    "        model = RACNet(NUM_CLASSES)\n",
    "        model = model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        criterion = F.cross_entropy\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model, \n",
    "            device, \n",
    "            optimizer, \n",
    "            criterion,\n",
    "            epochs,\n",
    "            LossMeter, \n",
    "            fold\n",
    "        )\n",
    "        \n",
    "        #trainer.fit(epochs,\n",
    "        #            train_loader,\n",
    "        #            './checkpoints/f\"best-model-{fold}.pth',\n",
    "        #            5)\n",
    "                        \n",
    "        #trainer.plot_loss()\n",
    "        #trainer.plot_score()\n",
    "        #trainer.plot_fscore()\n",
    "                \n",
    "        #test\n",
    "        loss, test_acc, test_f1, test_auroc = Trainer.test(test_loader)\n",
    "        #fold_loss.append(loss)\n",
    "        #fold_acc.append(test_acc)\n",
    "        #fold_f1.append(test_f1)\n",
    "        #fold_auroc.append(test_auroc)    \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    '''wandb.log({\n",
    "         'Avg Test f1 score': np.mean(test_fscore),\n",
    "         'Avg Train f1 score': np.mean(f_scores)\n",
    "         })'''\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print('Avg loss {:.5f}'.format(np.mean(losses)))\n",
    "    print('Avg score {:.5f}'.format(np.mean(scores)))\n",
    "    print('Avg Train f1_score {:.5f}'.format(np.mean(f_scores)))\n",
    "    print('Avg Test f1_score {:.5f}'.format(np.mean(test_fscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7b332-5d7a-4846-be16-ce5eb997b6bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(PATH, NUM_EPOCHS, KFOLD, BATCH_SIZE, NUM_WORKERS, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa8a9e-0f5e-49db-a7c1-cf5d380c653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff070a4-97ab-47fc-b89e-eb86a18bc9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a39bdd-30b2-423f-9273-83120b85bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e89e90-b548-487b-a8f8-594ab413b857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b854f-f286-461f-b24e-ab6d4aa3c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147b5f1-1ce3-4887-a0e2-d046f40e3930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5307b-e765-4e8a-978c-ed4a559e31d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43922d-cf92-4664-8054-2c175de2686b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87e121-fe17-4972-a838-e67240811a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab22c2-2a22-4b3c-b5cf-cb51887c1007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1ff0a-0a3d-4e5b-a4f2-455d31f3eddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da24c94-3a29-4f66-93b3-091cf9f2f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fold 3\n"
     ]
    }
   ],
   "source": [
    "folds_xtrain = np.load('./data/folds/xtrain.npy', allow_pickle=True)\n",
    "folds_xtest = np.load('./data/folds/xtest.npy', allow_pickle=True)\n",
    "folds_ytrain = np.load('./data/folds/ytrain.npy', allow_pickle=True)\n",
    "folds_ytest = np.load('./data/folds/ytest.npy', allow_pickle=True)\n",
    "\n",
    "xtrain = folds_xtrain[4]\n",
    "ytrain = folds_ytrain[4]\n",
    "xtest = folds_xtest[4]\n",
    "ytest = folds_ytest[4]\n",
    "\n",
    "print('-'*30)\n",
    "print(f\"Fold {'3'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a3c05b-4922-482d-aec8-152d40c21a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_retriever = RSNAdataset(\n",
    "    'data/reduced_dataset/',\n",
    "    xtrain,  \n",
    "    ytrain,\n",
    "    n_slices=254,\n",
    "    img_size=112,\n",
    "    transform=None\n",
    "        )\n",
    "\n",
    "test_retriever = RSNAdataset(\n",
    "    'data/reduced_dataset/',\n",
    "    xtest,  \n",
    "    ytest,\n",
    "    n_slices=254,\n",
    "    img_size=112,\n",
    "    transform=None\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_retriever,    \n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_retriever,    \n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "# Checking the dataset\n",
    "for batch in train_loader:  \n",
    "    print('Image batch dimensions:', batch['X'].shape)\n",
    "    print('Image Class dimensions:', batch['y'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3ccb3-f70c-47c1-b2b7-52d7a64472c3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b773e-0ed6-4539-b4df-377d4866274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RACNet(NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4b7f6-bf40-4a7d-a632-0e27f3964434",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(PATH, NUM_EPOCH, N_kFOLD, BATCH_SIZE, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5b05-17eb-42c4-a53a-15f708daf27b",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525a121-2caa-46c2-857d-411aae1eae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9279c8-5516-4908-86c3-db9f7caea158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecNet()\n",
    "model.to(device='cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = F.cross_entropy\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1650b-8b1b-4830-a17a-302439aa40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader, 1):\n",
    "    X = batch[0]['X'].to(device='cuda')\n",
    "    print('train_loader output',X.shape)\n",
    "    y = batch[0]['y'].to(device='cuda')\n",
    "    print('train_loader targets',y.shape)\n",
    "    org = batch[1][0]\n",
    "    print('train org', org)\n",
    "    #count += 1\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    outputs = model(X, org).squeeze(1)\n",
    "    break\n",
    "    #print('prob outputs', outputs.shape)\n",
    "    \n",
    "    #loss = criterion(outputs, y)\n",
    "    #loss.backward()\n",
    "\n",
    "    #train_loss.update(loss.detach().item())\n",
    "    #train_score.update(targets, outputs.detach())\n",
    "    \n",
    "    #self.optimizer.step()\n",
    "    \n",
    "    #_loss, _score = train_loss.avg, train_score.avg\n",
    "    #message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}, train_f1: {:.5f}'\n",
    "    #self.info_message(message, step, len(train_loader), _loss, _score, ff, end=\"\\r\")\n",
    "\n",
    "    #f_score = ff_score.get_score()\n",
    "    #return train_loss.avg, train_score.avg, f_score, int(time.time() - t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264f76d-8b75-4fc3-9ab7-70bda1eface7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b2d6a9-46bf-4d18-ac9b-a763b699f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict, org = train_retriever[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07ff37b-448a-4998-bdf5-0b1612bc38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dict['X']\n",
    "targets = dict['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacb7f55-52bc-4c85-a5f4-9c54157f6d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 1, 112, 112])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape\n",
    "#targets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1957793-d329-426b-93c5-336a290688f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbc7194-6d55-43e0-be38-c608ebab3e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22376b-155f-4e62-a416-cf7fedc97274",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = batch.to(device='cuda')\n",
    "X = X.unsqueeze(0)\n",
    "print(X.shape)\n",
    "y = targets.to(device='cuda')\n",
    "print(y.shape)\n",
    "\n",
    "#self.optimizer.zero_grad()\n",
    "outputs = model(X, org).squeeze()\n",
    "#outputs = outputs.squeeze()\n",
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef909f1e-8865-46d9-94ef-46f35e0ca4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('*convnext*', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d9bfd-6e91-4ec5-bd5d-b3d438e5051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4f61897-9036-4f2b-9b34-411ef52c4273",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled shape: 2048\n",
      "Identity()\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "res = timm.create_model('resnet50', pretrained=True, num_classes=0, in_chans=1)\n",
    "#m = res(torch.randn(2, 3, 224, 224))\n",
    "res.reset_classifier(0)\n",
    "o = res(torch.randn(2, 1, 112, 112))\n",
    "print(f'Pooled shape: {o.shape[1]}')\n",
    "print(res.fc)\n",
    "in_features = res(torch.randn(2, 1, 112, 112)).shape[1]\n",
    "print(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b43ceb-ee6e-4793-ab3b-f5c40ef81e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [torch.tensor(frame, dtype=torch.float32) for frame in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5abc94e3-6372-4562-9c0b-1f6c0a7adf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "073d78be-7900-41a5-89a0-bb7e04d6c7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 112, 112])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c0666-934a-4461-9e95-a8ea47e03f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a 'Karanjot Vendal' -v -p torch --iversion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

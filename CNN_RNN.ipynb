{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'! pip install lightning\\n! pip install torchmetrics\\n! pip install watermark\\n! pip install mlxtend\\n! pip install tensorboard\\n! pip install pandas'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''! pip install lightning\n",
    "! pip install torchmetrics\n",
    "! pip install watermark\n",
    "! pip install mlxtend\n",
    "! pip install pandas'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "'''import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger, CSVLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint'''\n",
    "\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datamodules import RSNAdataset\n",
    "from plotting import show_failures, plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaranjot\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/karanjotvendal/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key='a2a7828ed68b3cba08f2703971162138c680b664')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Karanjot Vendal\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.4\n",
      "IPython version      : 8.14.0\n",
      "\n",
      "torch: 2.0.1\n",
      "\n",
      "lightning   : 2.0.6\n",
      "timm        : 0.9.2\n",
      "pandas      : 2.0.3\n",
      "numpy       : 1.25.1\n",
      "matplotlib  : 3.7.2\n",
      "torchmetrics: 1.0.1\n",
      "torchvision : 0.15.2\n",
      "torch       : 2.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a 'Karanjot Vendal' -v -p torch --iversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/reduced_dataset/'\n",
    "MODEL = 'resnet18'\n",
    "BATCH_SIZE = 3\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m      2\u001b[0m       \u001b[38;5;66;03m# Set the project where this run will be logged\u001b[39;00m\n\u001b[1;32m      3\u001b[0m       project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRACNet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m       \u001b[38;5;66;03m# We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m       \u001b[38;5;66;03m# Track hyperparameters and run metadata\u001b[39;00m\n\u001b[1;32m      7\u001b[0m       config\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      8\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: LEARNING_RATE,\n\u001b[1;32m      9\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchitecture\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN-GRU-MASK-FC-Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMICAA MRI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: NUM_EPOCHS,\n\u001b[1;32m     12\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: BATCH_SIZE\n\u001b[1;32m     13\u001b[0m       })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"RACNet\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"experiment_{1}\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": LEARNING_RATE,\n",
    "      \"architecture\": \"CNN-GRU-MASK-FC-Classifier\",\n",
    "      \"dataset\": \"MICAA MRI\",\n",
    "      \"epochs\": NUM_EPOCHS,\n",
    "      \"BATCH_SIZE\": BATCH_SIZE\n",
    "      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RACNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = timm.create_model(MODEL, pretrained=True, num_classes=0, in_chans=1)\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "        in_features = self.cnn(torch.randn(2, 1, 112, 112)).shape[1]\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=in_features, hidden_size=64, batch_first= True, bidirectional=False)\n",
    "        \n",
    "        self.fc = nn.Linear(16256, 32, bias=True)\n",
    "        self.classifier = nn.Linear(32, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x, org):\n",
    "        # x shape: BxSxCxHxW\n",
    "        batch_size, slices, C, H, W = x.size()\n",
    "        c_in = x.view(batch_size * slices, C, H, W)\n",
    "        #print('reshape input', c_in.shape)\n",
    "        \n",
    "        out = self.cnn(c_in)\n",
    "        #print('CNN ouput', out.shape)\n",
    "        \n",
    "        rnn_in = out.view(batch_size, slices, -1)\n",
    "        #print('reshaped rnn_in', rnn_in.shape)\n",
    "        out, hd = self.rnn(rnn_in)\n",
    "        #out =F.relu(self.RNN(out))\n",
    "\n",
    "        #print('RNN ouput', out.shape)\n",
    "        mask = self.mask_layer(org)\n",
    "        out = out * mask\n",
    "        #print('mask ouput', out.shape)\n",
    "        \n",
    "        batch, slices, rnn_features = out.size()\n",
    "        out = out.reshape(batch_size, slices * rnn_features)\n",
    "        #print('reshaped masked output', out.shape)\n",
    "        \n",
    "        out = F.relu(self.fc(out))\n",
    "        #print('fc ouput', out.shape)\n",
    "        \n",
    "        logits = self.classifier(out)\n",
    "        #print('classifier ouput', logits.shape)\n",
    "        #output = F.softmax(logits, dim=1)\n",
    "        #[prob 0, prob 1]\n",
    "\n",
    "        return logits       \n",
    "\n",
    "    def mask_layer(self, org):\n",
    "        masks = []\n",
    "        org = org[0].cpu().numpy()\n",
    "        for i in org:\n",
    "            print(i)\n",
    "            dup = 254 - i\n",
    "            mask_1 = torch.ones(i, 64) # .to(device='cuda')\n",
    "            mask_0 = torch.zeros(dup, 64) #.to(device='cuda')\n",
    "            mask = torch.cat((mask_1, mask_0), 0)\n",
    "            masks.append(mask)\n",
    "\n",
    "        masks = torch.stack(masks).to(device='cuda')\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configuring the lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Configuring the lightning module\n",
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate, num_epochs, batch_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        #self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        \n",
    "        self.train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')\n",
    "        #self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')\n",
    "        self.test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro')\n",
    "\n",
    "        self.train_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2)\n",
    "        #self.val_auroc = AUROC(task=\"multiclass\", num_classes=2)\n",
    "        self.test_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "    def forward(self, x, org):\n",
    "        return self.model(x, org)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        dict = batch\n",
    "        features = dict['X']\n",
    "        print('input',features.shape)\n",
    "        true_labels = dict['y']\n",
    "        true_labels = true_labels.type(torch.cuda.LongTensor)\n",
    "        print('targets',true_labels.shape)\n",
    "        org = dict['org']\n",
    "        print('org', type(org))\n",
    "        out = self(features, org)\n",
    "\n",
    "        loss = F.cross_entropy(out, true_labels)\n",
    "        predicted_labels = torch.softmax(out, dim=1)\n",
    "        return loss, true_labels, predicted_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_acc(predicted_labels, true_labels)\n",
    "        self.log(\n",
    "            \"train_acc\", self.train_acc, prog_bar=True, on_epoch=True, on_step=False\n",
    "        )\n",
    "        self.train_f1(predicted_labels, true_labels)\n",
    "        self.log(\"train_f1\", self.train_f1, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "        self.train_auroc(predicted_labels, true_labels)\n",
    "        self.log(\"train_auroc\", self.train_auroc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    '''def validation_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=False)\n",
    "        self.val_acc(predicted_labels, true_labels)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=False)'''\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        self.test_acc(predicted_labels, true_labels)\n",
    "        self.log(\"test_acc\", self.test_acc, on_epoch=True)\n",
    "        \n",
    "        sef.test_f1(predicted_labels, true_labels)\n",
    "        self.log(\"train_f1\", self.test_f1, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "        self.test_auroc(predicted_labels, true_labels)\n",
    "        self.log(\"train_auroc\", self.test_auroc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RSNADataModule(L.LightningDataModule):\n",
    "    def __init__(self, fold, data_path=PATH, batch_size=10, num_workers=0, height_width=(112,112), mod=\"FLAIR\"):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = data_path\n",
    "        self.height_width = height_width\n",
    "        self.num_workers = num_workers\n",
    "        self.fold = fold\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \n",
    "        self.train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(self.height_width),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5), (0.5))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(self.height_width),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5), (0.5))\n",
    "            ]\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Note transforms.ToTensor() scales input images\n",
    "        # to 0-1 range\n",
    "        folds_xtrain = np.load('./data/folds/xtrain.npy', allow_pickle=True)\n",
    "        folds_xtest = np.load('./data/folds/xtest.npy', allow_pickle=True)\n",
    "        folds_ytrain = np.load('./data/folds/ytrain.npy', allow_pickle=True)\n",
    "        folds_ytest = np.load('./data/folds/ytest.npy', allow_pickle=True)\n",
    "        \n",
    "        xtrain = folds_xtrain[self.fold]\n",
    "        ytrain = folds_ytrain[self.fold]\n",
    "        xtest = folds_xtest[self.fold]\n",
    "        ytest = folds_ytest[self.fold]\n",
    "\n",
    "        \n",
    "        self.train = RSNAdataset(\n",
    "            self.data_path,\n",
    "            xtrain,  \n",
    "            ytrain,\n",
    "            n_slices=254,\n",
    "            img_size=112,\n",
    "            transform=None\n",
    "        )\n",
    "\n",
    "        self.test = RSNAdataset(\n",
    "            self.data_path,\n",
    "            xtest,  \n",
    "            ytest,\n",
    "            n_slices=254,\n",
    "            img_size=112,\n",
    "            transform=None\n",
    "        )\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            dataset=self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    '''def val_dataloader(self):\n",
    "        valid_loader = DataLoader(\n",
    "            dataset=self.valid,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "        return valid_loader'''\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(\n",
    "            dataset=self.test,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = RSNADataModule(4, PATH, BATCH_SIZE, NUM_WORKERS)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org tensor(40)\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    #train_counter.update(labels.tolist())\n",
    "    #print('X',batch['X'])\n",
    "    #print('y',batch['y'])\n",
    "    print('org',batch['org'][0][1])\n",
    "    #for i in batch['org']:\n",
    "    #    print(i.items())\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting up trainer and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wandb_logger = WandbLogger(\\n      project=\"RACNet\", \\n      name=f\"experiment_{2}\", \\n      # Track hyperparameters and run metadata\\n      config={\\n      \"learning_rate\": LEARNING_RATE,\\n      \"architecture\": \"CNN-LSTM\",\\n      \"dataset\": \"MICAA MRI\",\\n      \"epochs\": NUM_EPOCHS,\\n      \"batch size\": BATCH_SIZE,\\n      \"Image size\": (112,112)\\n      })'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#config lighnting module\n",
    "pymodel = RACNet(num_classes=NUM_CLASSES)\n",
    "lightning_model = LightningModel(pymodel, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "#checkpointing the best model\n",
    "#configuring earlystopping\n",
    "callbacks = [ModelCheckpoint(dirpath ='checkpoints/', \n",
    "                             filename= 'RACNet_fold{4}_f1:{train_f1}', \n",
    "                             save_top_k=1, mode='max', monitor='train_f1'),\n",
    "            TQDMProgressBar(refresh_rate=50),\n",
    "            EarlyStopping(monitor=\"train_loss\", mode=\"min\", patience=5)\n",
    "            ]\n",
    "\n",
    "#configuring logger\n",
    "csv_logger = CSVLogger(save_dir='csv_logs/', name='ResNet18')\n",
    "'''wandb_logger = WandbLogger(\n",
    "      project=\"RACNet\", \n",
    "      name=f\"experiment_{2}\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": LEARNING_RATE,\n",
    "      \"architecture\": \"CNN-LSTM\",\n",
    "      \"dataset\": \"MICAA MRI\",\n",
    "      \"epochs\": NUM_EPOCHS,\n",
    "      \"batch size\": BATCH_SIZE,\n",
    "      \"Image size\": (112,112)\n",
    "      })'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    callbacks = callbacks,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=[csv_logger],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | model       | RACNet             | 11.8 M\n",
      "1 | train_acc   | MulticlassAccuracy | 0     \n",
      "2 | test_acc    | MulticlassAccuracy | 0     \n",
      "3 | train_f1    | MulticlassF1Score  | 0     \n",
      "4 | test_f1     | MulticlassF1Score  | 0     \n",
      "5 | train_auroc | MulticlassAUROC    | 0     \n",
      "6 | test_auroc  | MulticlassAUROC    | 0     \n",
      "---------------------------------------------------\n",
      "631 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.8 M    Total params\n",
      "47.206    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                  | 0/156 [00:00<?, ?it/s]input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "100\n",
      "16\n",
      "108\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "101\n",
      "35\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "90\n",
      "101\n",
      "102\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "101\n",
      "96\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "98\n",
      "104\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "14\n",
      "33\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "31\n",
      "100\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "40\n",
      "101\n",
      "17\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "101\n",
      "34\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karanjotvendal/miniforge3/envs/thesis/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:42: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/karanjotvendal/miniforge3/envs/thesis/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:42: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "190\n",
      "49\n",
      "35\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "15\n",
      "52\n",
      "33\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "48\n",
      "34\n",
      "32\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "35\n",
      "105\n",
      "29\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "100\n",
      "172\n",
      "52\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "17\n",
      "33\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "20\n",
      "48\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "195\n",
      "106\n",
      "101\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "212\n",
      "35\n",
      "35\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "35\n",
      "15\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "19\n",
      "34\n",
      "16\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "104\n",
      "226\n",
      "105\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "35\n",
      "49\n",
      "35\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "100\n",
      "105\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "100\n",
      "34\n",
      "50\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "13\n",
      "16\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "207\n",
      "32\n",
      "101\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "16\n",
      "202\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "36\n",
      "12\n",
      "100\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "99\n",
      "35\n",
      "32\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "101\n",
      "51\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "96\n",
      "36\n",
      "32\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "106\n",
      "33\n",
      "33\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "117\n",
      "33\n",
      "24\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "95\n",
      "50\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "104\n",
      "17\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "100\n",
      "33\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "31\n",
      "105\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "101\n",
      "194\n",
      "53\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "102\n",
      "19\n",
      "31\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "106\n",
      "54\n",
      "18\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "32\n",
      "107\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "106\n",
      "32\n",
      "17\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "20\n",
      "35\n",
      "50\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "20\n",
      "103\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "22\n",
      "34\n",
      "18\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "92\n",
      "106\n",
      "104\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "107\n",
      "32\n",
      "35\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "92\n",
      "100\n",
      "12\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "91\n",
      "189\n",
      "203\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "17\n",
      "31\n",
      "99\n",
      "Epoch 0:  32%|████████████████████▏                                          | 50/156 [00:17<00:37,  2.85it/s, v_num=26]input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "105\n",
      "105\n",
      "51\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "23\n",
      "111\n",
      "16\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "109\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "22\n",
      "109\n",
      "100\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "107\n",
      "98\n",
      "35\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "35\n",
      "49\n",
      "103\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "105\n",
      "34\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "35\n",
      "31\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "204\n",
      "19\n",
      "95\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "32\n",
      "103\n",
      "14\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "14\n",
      "103\n",
      "51\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "102\n",
      "35\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "48\n",
      "15\n",
      "108\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "109\n",
      "17\n",
      "26\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "97\n",
      "50\n",
      "113\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "35\n",
      "14\n",
      "105\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "33\n",
      "16\n",
      "34\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "34\n",
      "115\n",
      "14\n",
      "input torch.Size([3, 254, 1, 112, 112])\n",
      "targets torch.Size([3])\n",
      "org <class 'list'>\n",
      "84\n",
      "11\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karanjotvendal/karanjot/thesis/RSNA/4 Task custom architecture/datamodules.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image, dtype=torch.float32) for image in images]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "trainer.fit(model=lightning_model, datamodule=dm)\n",
    "runtime = (time.time() - start_time)/60\n",
    "print(f'Training finished in {runtime: .2f} min in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting loss and accuracy\n",
    "plot_loss_and_acc(trainer.logger.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating accuracy of Best(Checkpoint) model on test set\n",
    "trainer.test(model=lightning_model, datamodule=dm, ckpt_path='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising cofusion matrix\n",
    "from torchmetrics import ConfusionMatrix\n",
    "import matplotlib\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "cmat = ConfusionMatrix(task='multiclass', num_classes=NUM_CLASSES)\n",
    "\n",
    "for x, y in dm.test_dataloader():\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = lightning_model(x)\n",
    "    cmat(pred, y)\n",
    "\n",
    "cmat_tensor = cmat.compute()\n",
    "cmat = cmat_tensor.numpy()\n",
    "\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=cmat,\n",
    "    class_names=class_dict.values(),\n",
    "    norm_colormap=matplotlib.colors.LogNorm()  \n",
    "    # normed colormaps highlight the off-diagonals \n",
    "    # for high-accuracy models better\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

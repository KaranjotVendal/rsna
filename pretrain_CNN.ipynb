{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KaranjotVendal\\mambaforge\\envs\\thesis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\KaranjotVendal\\mambaforge\\envs\\thesis\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "import wandb\n",
    "\n",
    "import torchmetrics\n",
    "import wandb\n",
    "\n",
    "from utils import load_image, LossMeter, save_metrics_to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # Hyperparameters\n",
    "    LEARNING_RATE = 0.0001\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_EPOCHS = 30\n",
    "    \n",
    "    # Other\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    NUM_WORKERS = 0\n",
    "\n",
    "    DATA_PATH = './data/archive'\n",
    "    IMG_SIZE = 112\n",
    "    WANDB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/archive\\no\\1 no.jpeg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/archive\\no\\10 no.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/archive\\no\\11 no.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/archive\\no\\12 no.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/archive\\no\\13 no.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>./data/archive\\yes\\Y95.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>./data/archive\\yes\\Y96.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>./data/archive\\yes\\Y97.JPG</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>./data/archive\\yes\\Y98.JPG</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>./data/archive\\yes\\Y99.JPG</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           paths labels\n",
       "0    ./data/archive\\no\\1 no.jpeg     no\n",
       "1    ./data/archive\\no\\10 no.jpg     no\n",
       "2    ./data/archive\\no\\11 no.jpg     no\n",
       "3    ./data/archive\\no\\12 no.jpg     no\n",
       "4    ./data/archive\\no\\13 no.jpg     no\n",
       "..                           ...    ...\n",
       "248   ./data/archive\\yes\\Y95.jpg    yes\n",
       "249   ./data/archive\\yes\\Y96.jpg    yes\n",
       "250   ./data/archive\\yes\\Y97.JPG    yes\n",
       "251   ./data/archive\\yes\\Y98.JPG    yes\n",
       "252   ./data/archive\\yes\\Y99.JPG    yes\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate data paths with labels\n",
    "data_dir = config.DATA_PATH\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "folds = [f for f in os.listdir(data_dir) if not f.startswith('.')]\n",
    "for fold in folds:\n",
    "    foldpath = os.path.join(data_dir, fold)\n",
    "    filelist = [f for f in os.listdir(foldpath) if not f.startswith('.')]\n",
    "    for file in filelist:\n",
    "        fpath = os.path.join(foldpath, file)\n",
    "        \n",
    "        filepaths.append(fpath)\n",
    "        labels.append(fold)\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths, name='paths')\n",
    "Lseries = pd.Series(labels, name='labels')\n",
    "df = pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/archive\\no\\1 no.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/archive\\no\\10 no.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/archive\\no\\11 no.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/archive\\no\\12 no.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/archive\\no\\13 no.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>./data/archive\\yes\\Y95.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>./data/archive\\yes\\Y96.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>./data/archive\\yes\\Y97.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>./data/archive\\yes\\Y98.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>./data/archive\\yes\\Y99.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           paths  labels\n",
       "0    ./data/archive\\no\\1 no.jpeg       0\n",
       "1    ./data/archive\\no\\10 no.jpg       0\n",
       "2    ./data/archive\\no\\11 no.jpg       0\n",
       "3    ./data/archive\\no\\12 no.jpg       0\n",
       "4    ./data/archive\\no\\13 no.jpg       0\n",
       "..                           ...     ...\n",
       "248   ./data/archive\\yes\\Y95.jpg       1\n",
       "249   ./data/archive\\yes\\Y96.jpg       1\n",
       "250   ./data/archive\\yes\\Y97.JPG       1\n",
       "251   ./data/archive\\yes\\Y98.JPG       1\n",
       "252   ./data/archive\\yes\\Y99.JPG       1\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " label_encoder = LabelEncoder()\n",
    " df['labels']= label_encoder.fit_transform(df['labels'])\n",
    " df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=0.7, shuffle=True, random_state=123, stratify=df['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainMRIdataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.paths = df['paths']\n",
    "        self.labels = df['labels']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths.iloc[idx]\n",
    "        image = load_image(path, size=(config.IMG_SIZE, config.IMG_SIZE))\n",
    "        if self.transform:\n",
    "           image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(self.labels.iloc[idx])\n",
    "        \n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([1, 112, 112])\n",
      "Image label dimensions: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "train_loader = BrainMRIdataset(df=train_df, transform=transforms.ToTensor())\n",
    "\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = timm.create_model('convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=True, num_classes=2, in_chans=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metrics(metrics, dataset_type, metric_name, value):\n",
    "    if dataset_type not in metrics:\n",
    "        metrics[dataset_type] = {}\n",
    "    \n",
    "    if metric_name not in metrics[dataset_type]:\n",
    "        metrics[dataset_type][metric_name] = []\n",
    "\n",
    "    metrics[dataset_type][metric_name].append(value)\n",
    "\n",
    "class TensorEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.tolist()\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        epochs,\n",
    "        loss_meter, \n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.epochs = epochs\n",
    "        self.loss_meter = loss_meter\n",
    "        self.hist = {'val_loss':[],\n",
    "                    'val_acc':[],\n",
    "                    'val_f1':[],\n",
    "                    'val_auroc':[],\n",
    "                    'train_loss':[],\n",
    "                    'train_acc':[],\n",
    "                    'train_f1': [],\n",
    "                    'train_auroc': [],\n",
    "                    }\n",
    "        \n",
    "        self.best_test_auroc = -np.inf\n",
    "        \n",
    "\n",
    "    def fit(self, train_loader, test_loader, save_path, patience = 0):\n",
    "        train_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            t = time.time()\n",
    "            self.model.train()\n",
    "            train_loss = self.loss_meter()\n",
    "            train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro').to(self.device)\n",
    "            train_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "            \n",
    "            for idx, (images, labels) in enumerate(train_loader):\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                logits = self.model(images)\n",
    "                #print(logits)\n",
    "                labels=labels.to(torch.int64)\n",
    "                \n",
    "                loss = self.criterion(logits, labels)\n",
    "                \n",
    "                train_loss.update(loss.detach().item())\n",
    "                train_acc.update(logits.detach(), labels)\n",
    "                train_f1.update(logits.detach(), labels)\n",
    "                train_auroc.update(logits.detach(), labels)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()  \n",
    "                \n",
    "            _loss = train_loss.avg\n",
    "            _acc = train_acc.compute()\n",
    "            _f1 = train_f1.compute()\n",
    "            _roc = train_auroc.compute()\n",
    "\n",
    "            if config.WANDB:\n",
    "                wandb.log({'train loss': _loss,\n",
    "                        'train acc': _acc,\n",
    "                        'train f1_score': _f1,\n",
    "                        'train AUROC': _roc\n",
    "                        })\n",
    "\n",
    "            train_acc.reset()\n",
    "            train_f1.reset()\n",
    "            train_auroc.reset()\n",
    "            \n",
    "            self.hist['train_loss'].append(_loss)\n",
    "            self.hist['train_acc'].append(_acc)\n",
    "            self.hist['train_f1'].append(_f1)\n",
    "            self.hist['train_auroc'].append(_roc)\n",
    "            \n",
    "            print(f' Train Epoch: {epoch+1}/{self.epochs} | Loss: {_loss:.5f} | Accuracy: {_acc:.4f}% | F1 Score: {_f1:.4f} | AUROC: {_roc:.4f} | Time: {time.time() - t}')\n",
    "            \n",
    "            val_loss, val_acc, val_f1, val_auroc = self.validate(test_loader, save_path)\n",
    "            \n",
    "            self.hist['val_loss'].append(val_loss)\n",
    "            self.hist['val_acc'].append(val_acc)\n",
    "            self.hist['val_f1'].append(val_f1)\n",
    "            self.hist['val_auroc'].append(val_auroc)\n",
    "            \n",
    "        \n",
    "        avg_loss = torch.mean(torch.tensor(self.hist['train_loss']))\n",
    "        avg_acc = torch.mean(torch.tensor(self.hist['train_acc']))\n",
    "        avg_f1 = torch.mean(torch.tensor(self.hist['train_f1']))\n",
    "        avg_auroc = torch.mean(torch.tensor(self.hist['train_auroc']))\n",
    "\n",
    "        print(f'Training Time: {(time.time() - train_time) // 60:.0f}m {(time.time() - train_time) % 60:.0f}s | Avg Loss: {avg_loss:.5f} | Avg Accuracy: {avg_acc:.3f}% | Avg F1 Score: {avg_f1:.4f} | Avg AUROC:{avg_auroc:.4f}')\n",
    "        \n",
    "            \n",
    "    \n",
    "    def validate(self, test_loader, save_path):\n",
    "        test_time = time.time()\n",
    "        self.model.eval()\n",
    "\n",
    "        val_loss = self.loss_meter()    \n",
    "        val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "        val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=2, average='macro').to(self.device)       \n",
    "        val_auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=2).to(self.device)\n",
    "\n",
    "        test_pred = []\n",
    "        test_targets = []\n",
    "        preds = []        \n",
    "        for idx, (images, labels) in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(torch.int64).to(self.device)\n",
    "                \n",
    "                logits = self.model(images)\n",
    "                \n",
    "                loss = self.criterion(logits, labels)\n",
    "                \n",
    "                val_loss.update(loss.detach().item())\n",
    "                \n",
    "                test_targets.append(labels)\n",
    "                preds.append(logits.detach())\n",
    "                \n",
    "                \n",
    "        test_targets = torch.cat(test_targets).flatten()\n",
    "        preds = torch.cat(preds)\n",
    "\n",
    "        \n",
    "        loss = val_loss.avg\n",
    "        acc = val_acc(preds, test_targets)\n",
    "        f1 = val_f1(preds, test_targets)\n",
    "        auroc = val_auroc(preds, test_targets)             \n",
    "                \n",
    "        if auroc > self.best_test_auroc: \n",
    "            self.best_test_auroc = auroc\n",
    "            \n",
    "            base_dir = \"./data/pretrain_convnext/\"\n",
    "            if not os.path.exists(base_dir):\n",
    "                os.mkdir(base_dir)\n",
    "\n",
    "            torch.save({\"model_state_dict\": self.model.state_dict(),\n",
    "                        \"best_auroc\": self.best_test_auroc,\n",
    "                        },\n",
    "                        save_path)\n",
    "                    \n",
    "            print(f'Checkpoint saved at {save_path} '\n",
    "                f'| Test acc: {acc :.2f}% '\n",
    "                f'| Test F1: {f1 :.3f}% '\n",
    "                f'| Best AUROC: {self.best_test_auroc:.3f}')           \n",
    "            \n",
    "        val_acc.reset()\n",
    "        val_f1.reset()\n",
    "        val_auroc.reset()\n",
    "            \n",
    "        if config.WANDB:\n",
    "            wandb.log({'val loss':loss,\n",
    "                    'val acc': acc,\n",
    "                    'val f1_score': f1,\n",
    "                    'val AUROC': auroc\n",
    "                    })\n",
    "\n",
    "        print(f\"Validation Epoch: {(time.time() - test_time) // 60:.0f}m {(time.time() - test_time) % 60:.0f}s | Accuracy: {acc:.2f}% | F1 Score: {f1:.4f} | AUROC: {auroc:.4f}\")\n",
    "        return loss, acc.item(), f1.item(), auroc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    '''if config.TRANSFORM:\n",
    "        train_transform = .Compose([\n",
    "                                    #A.HorizontalFlip(p=0.5),\n",
    "                                    A.Rotate(limit=10, p=0.5)\n",
    "                                ])\n",
    "    else:\n",
    "        train_transform = None'''\n",
    "\n",
    "    metrics = {\n",
    "    'train': {'loss': [], 'acc': [], 'f1': [], 'auroc': []},\n",
    "    'valid': {'loss': [], 'acc': [], 'f1': [], 'auroc': []},\n",
    "    }\n",
    "\n",
    "    train_set = BrainMRIdataset(\n",
    "                    train_df,\n",
    "                    transform=transforms.ToTensor()\n",
    "                        )\n",
    "                    \n",
    "    test_set = BrainMRIdataset(\n",
    "                    test_df,\n",
    "                    transform=transforms.ToTensor()\n",
    "                        )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "                train_set,    \n",
    "                batch_size=config.BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=config.NUM_WORKERS,\n",
    "            )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "                test_set,    \n",
    "                batch_size=config.BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=config.NUM_WORKERS,\n",
    "            )\n",
    "    \n",
    "    model = timm.create_model('convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=True, num_classes=2, in_chans=1)\n",
    "    \n",
    "    model = model.to(config.DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    criterion = F.cross_entropy\n",
    "    trainer = Trainer(\n",
    "                model, \n",
    "                config.DEVICE, \n",
    "                optimizer, \n",
    "                criterion,\n",
    "                config.NUM_EPOCHS,\n",
    "                LossMeter,\n",
    "                )\n",
    "    \n",
    "\n",
    "    trainer.fit(train_loader,\n",
    "                test_loader,\n",
    "                save_path = f'./data/pretrain_convnext/ConvNext_finetuned_model_best_auroc.pth',\n",
    "                )\n",
    "\n",
    "    for value in trainer.hist['train_loss']:\n",
    "        update_metrics(metrics, 'train', 'loss', value)\n",
    "\n",
    "    for value in trainer.hist['train_acc']:\n",
    "        update_metrics(metrics, 'train', 'acc', value)\n",
    "\n",
    "    for value in trainer.hist['train_f1']:\n",
    "        update_metrics(metrics, 'train', 'f1', value)\n",
    "\n",
    "    for value in trainer.hist['train_auroc']:\n",
    "        update_metrics(metrics, 'train', 'auroc', value)\n",
    "\n",
    "    for value in trainer.hist['val_loss']:\n",
    "        update_metrics(metrics, 'valid', 'loss', value)\n",
    "\n",
    "    for value in trainer.hist['val_acc']:\n",
    "        update_metrics(metrics, 'valid', 'acc', value)\n",
    "\n",
    "    for value in trainer.hist['val_f1']:\n",
    "        update_metrics(metrics, 'valid', 'f1', value)\n",
    "\n",
    "    for value in trainer.hist['val_auroc']:\n",
    "        update_metrics(metrics, 'valid', 'auroc', value)\n",
    "    \n",
    "    json_path = save_metrics_to_json(metrics, 'ft_convnext')\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n",
    "    \n",
    "    if config.WANDB:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 1/30 | Loss: 0.75728 | Accuracy: 0.4915% | F1 Score: 0.4794 | AUROC: 0.5059 | Time: 2.8602168560028076\n",
      "Checkpoint saved at ./data/pretrain_convnext/ConvNext_finetuned_model_best_auroc.pth | Test acc: 0.76% | Test F1: 0.695% | Best AUROC: 0.957\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.76% | F1 Score: 0.6946 | AUROC: 0.9574\n",
      " Train Epoch: 2/30 | Loss: 0.38570 | Accuracy: 0.8531% | F1 Score: 0.8398 | AUROC: 0.9452 | Time: 0.8585059642791748\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.86% | F1 Score: 0.8532 | AUROC: 0.9479\n",
      " Train Epoch: 3/30 | Loss: 0.22405 | Accuracy: 0.9492% | F1 Score: 0.9472 | AUROC: 0.9914 | Time: 0.8619987964630127\n",
      "Checkpoint saved at ./data/pretrain_convnext/ConvNext_finetuned_model_best_auroc.pth | Test acc: 0.84% | Test F1: 0.825% | Best AUROC: 0.971\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.84% | F1 Score: 0.8246 | AUROC: 0.9714\n",
      " Train Epoch: 4/30 | Loss: 0.11587 | Accuracy: 0.9661% | F1 Score: 0.9638 | AUROC: 1.0000 | Time: 0.8490002155303955\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.93% | F1 Score: 0.9315 | AUROC: 0.9640\n",
      " Train Epoch: 5/30 | Loss: 0.04073 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8598604202270508\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.89% | F1 Score: 0.8920 | AUROC: 0.9596\n",
      " Train Epoch: 6/30 | Loss: 0.02965 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8540282249450684\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.93% | F1 Score: 0.9315 | AUROC: 0.9677\n",
      " Train Epoch: 7/30 | Loss: 0.00978 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.843989372253418\n",
      "Checkpoint saved at ./data/pretrain_convnext/ConvNext_finetuned_model_best_auroc.pth | Test acc: 0.95% | Test F1: 0.944% | Best AUROC: 0.974\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9442 | AUROC: 0.9743\n",
      " Train Epoch: 8/30 | Loss: 0.00800 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8432450294494629\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.92% | F1 Score: 0.9152 | AUROC: 0.9736\n",
      " Train Epoch: 9/30 | Loss: 0.00876 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8439064025878906\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.92% | F1 Score: 0.9152 | AUROC: 0.9743\n",
      " Train Epoch: 10/30 | Loss: 0.00353 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.845860481262207\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.96% | F1 Score: 0.9584 | AUROC: 0.9714\n",
      " Train Epoch: 11/30 | Loss: 0.00181 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8340001106262207\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.96% | F1 Score: 0.9584 | AUROC: 0.9692\n",
      " Train Epoch: 12/30 | Loss: 0.00117 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.844001054763794\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9707\n",
      " Train Epoch: 13/30 | Loss: 0.00087 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8424010276794434\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9743\n",
      " Train Epoch: 14/30 | Loss: 0.00077 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8555779457092285\n",
      "Checkpoint saved at ./data/pretrain_convnext/ConvNext_finetuned_model_best_auroc.pth | Test acc: 0.95% | Test F1: 0.945% | Best AUROC: 0.976\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9758\n",
      " Train Epoch: 15/30 | Loss: 0.00082 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8569996356964111\n",
      "Checkpoint saved at ./data/pretrain_convnext/ConvNext_finetuned_model_best_auroc.pth | Test acc: 0.93% | Test F1: 0.932% | Best AUROC: 0.978\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.93% | F1 Score: 0.9315 | AUROC: 0.9780\n",
      " Train Epoch: 16/30 | Loss: 0.00061 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8349874019622803\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.92% | F1 Score: 0.9183 | AUROC: 0.9780\n",
      " Train Epoch: 17/30 | Loss: 0.00056 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8483610153198242\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.92% | F1 Score: 0.9183 | AUROC: 0.9780\n",
      " Train Epoch: 18/30 | Loss: 0.00047 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8519992828369141\n",
      "Checkpoint saved at ./data/pretrain_convnext/ConvNext_finetuned_model_best_auroc.pth | Test acc: 0.92% | Test F1: 0.918% | Best AUROC: 0.979\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.92% | F1 Score: 0.9183 | AUROC: 0.9787\n",
      " Train Epoch: 19/30 | Loss: 0.00038 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8650012016296387\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.92% | F1 Score: 0.9183 | AUROC: 0.9787\n",
      " Train Epoch: 20/30 | Loss: 0.00034 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8440001010894775\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.92% | F1 Score: 0.9183 | AUROC: 0.9787\n",
      " Train Epoch: 21/30 | Loss: 0.00031 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8540010452270508\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.93% | F1 Score: 0.9315 | AUROC: 0.9780\n",
      " Train Epoch: 22/30 | Loss: 0.00026 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8507895469665527\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      " Train Epoch: 23/30 | Loss: 0.00027 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.841588020324707\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      " Train Epoch: 24/30 | Loss: 0.00024 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.84800124168396\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      " Train Epoch: 25/30 | Loss: 0.00021 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8549520969390869\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      " Train Epoch: 26/30 | Loss: 0.00021 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8509998321533203\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      " Train Epoch: 27/30 | Loss: 0.00020 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8399999141693115\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9773\n",
      " Train Epoch: 28/30 | Loss: 0.00018 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8479993343353271\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      " Train Epoch: 29/30 | Loss: 0.00017 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8499917984008789\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      " Train Epoch: 30/30 | Loss: 0.00018 | Accuracy: 1.0000% | F1 Score: 1.0000 | AUROC: 1.0000 | Time: 0.8520739078521729\n",
      "Validation Epoch: 0m 0s | Accuracy: 0.95% | F1 Score: 0.9449 | AUROC: 0.9780\n",
      "Training Time: 0m 32s | Avg Loss: 0.05311 | Avg Accuracy: 0.975% | Avg F1 Score: 0.9743 | Avg AUROC:0.9814\n",
      "Saving metrics_ft_convnext.json\n",
      "\n",
      "Training complete in 0m 32s\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
